# 로그 수집

운영 중인 서비스에 문제가 생겨 로그를 확인해야 할 때가 있다. 클라우드 컴퓨터를 이용해서 서비스를 운영하고 있다면 로그를 확인하기 위해 SSH 접속을 해서 파일에 있는 내용을 검색해봐야 한다. 이런 방식은 번거롭고 효율적이지 못하다. 

만약 서비스가 로드밸런싱 되어 여러 대의 서버가 운영 중이라면 로그를 확인하기 위해 각 서버에 접속해야 한다. SSH로 접속해서 확인하는 건 여전히 가능하지만 더욱 비효율적인 확인 절차를 거쳐야 한다.

이런 비효율적인 작업을 개선하기 위해서 각 서버의 로그들을 중앙화된 저장소에 모아서 관리하는게 필요한데 이를 로그 수집이다. 그리고 로그 수집에 많이 활용되는 저장소는 엘라스틱서치가 있다.

그런데 로그는 때로 가공이 필요하기 때문에 로그 수집을 위한 도구로 로그스태시를 사용한다. 로그스태시는 로그를 수집하고 필요한 가공을 할 수 있는 도구이다. 로그스태시는 엘라스틱서치와 함께 사용되는 경우가 많다.

수집되는 과정을 설계할 때 로그스태시가 로그 파일을 읽어서 엘라스틱서치에 저장하도록 하는 게 가장 좋지만 먼저 간단한 설계를 위해 Logback Appender가 Logstash로 로그를 전송하는 것으로 수집이 시작되도록 한다.

## Logstash, Elasticsearch 준비하기

도커로 간단하게 Logstash와 Elasticsearch를 실행할 수 있다. 아래와 같이 `docker-compose.yml` 파일을 작성한다.

```yaml
version: '3'
services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.http.ssl.enabled=false
    ports:
      - 9200:9200
    networks:
      - elk
    restart: unless-stopped

  logstash:
    image: docker.elastic.co/logstash/logstash:8.10.0
    container_name: logstash
    ports:
      - "5044:5044"
      - "9600:9600"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    networks:
      - elk
    restart: unless-stopped
```

Logback Appender로 Logstash에 전송할 것이니까 애플리케이션에 의존성을 추가해주어야 한다.

### Logstash 의존성 추가

```groovy
dependencies {
    implementation 'net.logstash.logback:logstash-logback-encoder:7.4'
}
```

그리고 Appender를 추가해주자.

### Logstash Appender 추가(logback.xml)

```xml
<configuration>
    <property name="LOG_FILE" value="application.log"/>

    <!-- Logstash로 전송할 Appender -->
    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <destination>localhost:5044</destination>
        <encoder class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>

    <!-- 콘솔 출력 -->
    <appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} %-5level [%thread] %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- 파일 출력 -->
    <appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_FILE}</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>application.%d{yyyy-MM-dd_HH-mm}.log.gz</fileNamePattern>
            <maxHistory>5</maxHistory>
        </rollingPolicy>
        <encoder>
            <pattern>%d{yyyy-MM-dd HH:mm:ss} %-5level [%thread] %logger{36} - %msg%n</pattern>
        </encoder>
    </appender>

    <!-- Logger 설정 -->
    <root level="info">
        <appender-ref ref="CONSOLE" />
        <appender-ref ref="FILE" />
        <appender-ref ref="LOGSTASH" />
    </root>
</configuration>
```

Logstash 실행 설정 파일을 추가해주자.

### Logstash 실행 설정 파일(logstash.conf)

```conf
input {
    tcp {
        port => 5044
        codec => json
    }
}

output {
    elasticsearch {
        hosts => ["http://elasticsearch:9200"]
        index => "application-logs-%{+YYYY.MM.dd}"
    }
}
```

input에 port에는 어떤 포트로 input이 들어오는지와 codec에 어떤 파일 형태로 로그가 들어오는지 명시해줘야 하는데 Logback Appender에 설정한 LogstashEncoder를 사용하면 로그가 json 형태로 인코딩되기에 json이라 명시해준다.

output으로는 hosts에 output을 보낼 호스트를 지정하고 index에 어떤 인덱스로 저장할 것인지 명시해준다. 호스트는 지금 도커 네트워크로 엘라스틱 서치가 묶여 있으니 `http://elasticsearch:9200`로 설정해준다. 인덱스는 날짜별로 저장하도록 설정해준다. 엘라스틱서치에서 index라는 개념은 데이터가 저장될 수 있는 공간 개념이다.


이 실행 파일의 위치는 docker-compose.yml에 작성한 것과 일치시켜줘야 한다.

여기까지의 설정을 완료하고 애플리케이션을 실행시키면 로그가 Logstash로 전송되고 Logstash는 Elasticsearch에 저장하게 된다. 이후에는 Kibana를 이용해서 로그를 확인할 수 있다.

> 엘라스틱서치에 저장된 로그를 확인하기 위해서는 `http://localhost:9200/_cat/indices`로 접속하면 인덱스 목록을 확인할 수 있다.