# Thread-per-Request 모델에서 실제로는 컨텍스트 스위칭이 생겨나는 이유
## 1. 컨텍스트 스위칭이 발생하는 주요 원인
1. **멀티스레드 환경의 특성**  
    Thread-per-Request 모델은 각 요청마다 새로운 스레드를 생성하거나 스레드 풀에서 스레드를 할당한다. 동시에 여러 요청을 처리하게 되면 여러 스레드가 동시에 실행되어야 하는데, 물리적인 CPU 코어 수보다 스레드 수가 많은 경우가 대부분이다.

2. **CPU 코어 수의 제한**  
   예를 들어 4개의 CPU 코어가 있는 시스템에서 100개의 요청이 동시에 들어온다면, 100개의 스레드가 4개의 코어를 두고 경쟁해야 한다. 운영체제는 이런 상황에서 시간 분할(time slicing) 방식으로 각 스레드에게 CPU 시간을 할당한다.

3. **스레드 스케줄링 과정에서의 컨텍스트 스위칭**
- **선점형 스케줄링**: 운영체제가 각 스레드에게 일정한 시간 슬라이스를 할당하고, 시간이 끝나면 다른 스레드로 교체 
- **I/O 대기**: 스레드가 데이터베이스 쿼리나 파일 읽기 등의 I/O 작업을 수행할 때 블로킹되면, CPU는 다른 스레드로 전환 
- **동기화 대기**: 스레드가 락(lock)이나 세마포어 등을 기다릴 때 블로킹되면 컨텍스트 스위칭 발생

## 2. 컨텍스트 스위칭의 구체적인 과정
```
스레드 A (요청 1 처리 중) → I/O 작업 시작 → 블로킹 상태
    ↓
운영체제가 스레드 A의 상태를 저장하고 스레드 B로 전환
    ↓
스레드 B (요청 2 처리 중) → 시간 슬라이스 만료
    ↓
스레드 B의 상태를 저장하고 스레드 C로 전환
    ↓
이런 식으로 계속 순환...
```

## 3. 컨텍스트 스위칭의 비용
1. **상태 저장 및 복원 비용**
   - 레지스터 값, 프로그램 카운터, 스택 포인터 등을 저장하고 복원 
   - 메모리 관리 정보 (페이지 테이블 등) 변경
2. 캐시 미스 증가 
   - 새로운 스레드가 실행될 때 기존 캐시 데이터가 무효화됨 
   - 메모리 접근 시간이 증가
3. 스케줄링 오버헤드
   - 다음에 실행할 스레드를 결정하는 과정에서 발생하는 비용

이러한 이유로 Thread-per-Request 모델은 동시 요청 수가 많아질수록 컨텍스트 스위칭 비용이 급격히 증가하여 성능 저하를 일으킨다. 이를 해결하기 위해 비동기 I/O 모델이나 이벤트 루프 기반의 아키텍처가 등장하게 되었다.


# 모델 자체는 요청을 받아 응답을 하기까지 같은 스레드를 갖는다는게 이론인게 맞을까?

맞다. Thread-per-Request 모델의 핵심 이론은 하나의 요청이 처리 완료될 때까지 동일한 스레드에서 모든 작업을 수행한다는 것이다.

## 1. Thread-per-Request 모델의 기본 원리
요청의 전체 생명주기가 하나의 스레드에서 처리된다:

```
HTTP 요청 수신 → 요청 파싱 → 비즈니스 로직 실행 → DB 쿼리 → 응답 생성 → 응답 전송
↑___________________________ 모두 동일한 스레드 ___________________________↓
```

## 2. 스레드와 요청의 1:1 대응
이상적인 시나리오:
- 요청 A → 스레드 1에서 처리 완료까지
- 요청 B → 스레드 2에서 처리 완료까지
- 요청 C → 스레드 3에서 처리 완료까지

각 스레드는 자신이 담당한 요청을 끝까지 처리하고, 다른 스레드로 넘어가지 않습니다.

## 3. 그럼에도 컨텍스트 스위칭이 발생하는 이유
1. **물리적 제약**
   - CPU 코어 수 < 동시 실행 스레드 수
   - 4개 코어에서 100개 스레드가 동시 실행 → 스케줄링 필요
2. I/O 블로킹
    ```java
    // 스레드 1에서 실행
    public void handleRequest() {
    // 1. 요청 처리 (CPU 사용)
    processRequest();
    
        // 2. DB 쿼리 (I/O 블로킹) → 이때 컨텍스트 스위칭!
        String result = database.query("SELECT ...");
        
        // 3. 응답 생성 (CPU 사용) → I/O 완료 후 다시 이 스레드로 돌아옴
        generateResponse(result);
    }
    ```
3. 시간 분할 스케줄링
   - 각 스레드가 CPU를 독점하지 않도록 일정 시간마다 교체
   
## 핵심 포인트
Thread-per-Request 모델에서 "**요청-스레드 바인딩**"은 유지되지만, 물리적 CPU 실행 시점에서는 컨텍스트 스위칭이 발생한다. 즉:
- **논리적으로**: 요청 A는 스레드 1에서만 처리 
- **물리적으로**: 스레드 1이 항상 CPU를 점유하지는 못함

이것이 Thread-per-Request 모델의 성능 한계가 되는 이유이다. 스레드는 요청과 바인딩되어 있지만, I/O 대기 중에도 메모리를 점유하고 있으면서 실제로는 CPU를 사용하지 않는 비효율이 발생한다.


# 요청-스레드 바인딩이 유지된다?
컨텍스트 스위칭이 발생해도 요청과 스레드의 논리적 관계는 변하지 않는다:

```
요청 A가 스레드 1에 할당됨
    ↓
스레드 1이 DB 쿼리로 블로킹 → 컨텍스트 스위칭으로 CPU에서 제거
    ↓
스레드 2, 3, 4가 CPU에서 실행...
    ↓
DB 쿼리 완료 → 스레드 1이 다시 CPU로 복귀
    ↓
스레드 1이 요청 A의 나머지 로직 계속 수행
```

## 1. 스레드의 상태 변화
**스레드 1의 관점에서**:
```java
public void handleRequest() {
    // 1. CPU에서 실행 중
    log("요청 파싱 시작");

    // 2. I/O 블로킹 → WAITING 상태로 변경 (CPU 반납)
    String result = database.query("SELECT ...");
    
    // 3. I/O 완료 → RUNNABLE 상태로 변경 → 스케줄링 대기
    // 4. CPU 재할당 → 다시 RUNNING 상태
    log("DB 결과: " + result);  // 여전히 같은 스레드!
    
    // 5. 응답 완료까지 계속 이 스레드에서 처리
    response.send(result);
}
```

## 2. 핵심 차이점
**바인딩 유지 vs CPU 점유**:
- 바인딩: 요청 A는 처음부터 끝까지 스레드 1 소유 
- CPU 점유: 스레드 1이 항상 CPU를 사용하지는 않음

**스레드 로컬 변수 예시**:
```java
public class RequestHandler {
    private static final ThreadLocal<String> requestId = new ThreadLocal<>();

    public void handleRequest() {
        requestId.set("REQ-123");  // 스레드 1에 저장
        
        database.query("SELECT ...");  // 블로킹 → 컨텍스트 스위칭
        
        // I/O 완료 후 다시 이 스레드로 돌아옴
        String id = requestId.get();   // 여전히 "REQ-123"
        log("같은 스레드입니다: " + id);
    }
}
```

## 3. 다른 모델과의 차이
**비동기 모델 (예: Node.js)**:
```javascript
// 요청 A가 들어옴
app.get('/api', (req, res) => {
    // 이벤트 루프 스레드에서 시작
    db.query("SELECT ...", (result) => {
    // 콜백은 다른 시점에, 가능하면 다른 스레드에서 실행될 수 있음
    res.send(result);
    });
});
```

즉, Thread-per-Request 모델에서는 컨텍스트 스위칭이 발생해도 요청의 전체 생명주기가 동일한 스레드에서 처리되는 것이 핵심 특징이다.