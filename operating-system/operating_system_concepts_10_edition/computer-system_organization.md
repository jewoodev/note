# 1.2 Computer-System Organization

## 1.2.1 Interrupts
일반적인 컴퓨터 작업, I/O 프로그래밍 성능을 생각해보자. I/O 작업을 시작하려면, 장치 드라이버는 장치 컨트롤러에 있는 적절한 레지스터를 읽어들여야 한다.  
그 장치 컨트롤러는, 순서대로 레지스터의 항목들을 검증한다, 무슨 행동을 취해야 할지 정하기 위해. 컨트롤러가 자신의 버퍼로부터 데이터를 가져오기 시작한다.  
데이터의 이동이 완료되면, 장치 컨트롤러는 장치 드라이버에게 작업이 끝났음을 알린다. 그럼 드라이버는 제어권을 운영체제의 다른 부분에 줘서 데이터 혹은 데이터의 포인터를 돌려받을 수 있도록 한다(작업이 읽기 작업이었다면).

다른 작업에서는, 장치 드라이버는 "쓰기 작업이 성공적으로 완료되었다" 와 같은 상태 정보를 반환한다. 그런데 컨트롤러가 드라이버에게 작업이 끝났음을 알려주는 방법이 뭘까? 
바로 interrupt를 일으키는 것이다.

### 1.2.1.1 Overview
Interrupt는 많은 목적을 위해 사용되기도 하며, 운영체제와 하드웨어가 상호 작용하는데 중요한 **열쇠**이기도 하다.

CPU에 interrupt가 일어나면 하던 일을 멈추고 즉시 고정된 위치로 실행에 대한 정보를 이동시킨다. 이 고정된 위치는 보통 시작 주소(interrupt가 일어난 서비스 루틴이 위치한)를 가지고 있다.

Interrupt는 제어권을 적절한 interrupt 서비스 루틴에 넘겨야 한다. 이 전송을 관리하는 간단한 방법은 인터럽트 정보를 조사하기 위해 일반 루틴을 호출하는 것이다.

루틴은 순서대로 인터럽트-특정 핸들러를 호출한다.
하지만, 인터럽트는 자주 일어나는 만큼 빠르게 처리되어야만 한다.
Interrupt 루틴에 대한 포인터 테이블을 대체재로 사용해서 필요한 속도를 제공할 수 있다.   
Interrupt 루틴은 그 테이블에 의해 간접적으로 호출되는데, 이 호출 이전에 사전 호출이 필요하지 않다.  
일반적으로, 포인터 테이블은 낮은 메모리에 저장된다(0부터 100 번 정도의 메모리 공간에).  
이 위치들은 다양한 장치를 위한 인터럽트 서비스 루틴의 주소를 가지고 있다.  
이 주소들의 배열, 혹은 인터럽트 벡터는 고유한 숫자와 주어진 인터럽트 요청과 함께 인덱싱된다, 인터럽트하고 있는 장치를 위한 인터럽트 서비스 루틴 주소를 제공하기 위해서.   
윈도우와 유닉스와 같은 서로 다른 운영 체제도 이런 방식으로 인터럽트를 처리한다.

인터럽트 아키텍처는 인터럽트가 발생한 항목의 상태 정보를 저장해야 하며, 인터럽트를 처리한 후 이 정보를 복원할 수 있어야 한다.  
인터럽트 루틴이 프로세서 상태를 수정해야 하는 경우(예: 레지스터 값 수정) 현재 상태를 명시적으로 저장한 다음 반환하기 전에 해당 상태를 복원해야 한다.  
인터럽트가 처리된 후, 저장된 반환 주소가 프로그램 카운터에 로드되고, 인터럽트가 발생하지 않은 것처럼 중단된 계산이 재개된다.

### 1.2.1.2 Implementation
기본적인 인터럽트 메커니즘은 다음과 같이 작동한다. 

CPU 하드웨어에는 CPU가 모든 명령어를 실행한 후 감지하는 인터럽트 요청 회선이라는 전선이 있다.  
CPU가 컨트롤러가 인터럽트 요청 회선에서 신호를 보낸 걸 감지하면 인터럽트 번호를 읽고 해당 인터럽트 번호를 인터럽트 벡터의 인덱스로 사용하여 인터럽트 핸들러 루틴으로 점프한다.  
그런 다음 해당 인덱스와 연관된 주소에서 실행을 시작한다.   
인터럽트 핸들러는 작업 중에 변경되는 모든 상태를 저장하고, 인터럽트의 원인을 확인하고, 필요한 처리를 수행하고, 상태 복구를 수행하고, return_from_interrupt 명령어를 실행하여 CPU를 인터럽트 이전의 실행 상태로 되돌린다.  
정리하면, 장치 컨트롤러가 인터럽트 요청 라인에서 신호를 보내서 인터럽트를 발생시키고, CPU가 인터럽트를 포착하여 인터럽트 핸들러로 전송하고, 핸들러가 장치에 서비스를 제공하여 인터럽트를 지운다.  

기본적인 인터럽트 메커니즘은 장치 컨트롤러가 서비스 준비가 된 것 처럼 비동기적인 이벤트에 CPU가 응답할 수 있도록 해준다. 그러나 현대적인 운영체제에서는 보다 정교한 인터럽트 처리 기능이 필요하다.

1. 중요한 처리가 진행되는 동안 인터럽트 처리를 연기할 수 있는 기능이 필요하다.
2. 장치에 알맞은 interrupt handler가 무엇인지 알아내는 효율적인 방법이 필요하다.
3. 운영체제가 높은 우선순위의 인터럽트와 낮은 우선순위의 인터럽트를 구별하고, 적절한 긴급성 수준으로 대응할 수 있도록 다단계 인터럽트 기능이 필요하다.

현대의 컴퓨터 하드웨어는 세가지 기능을 제공한다, CPU와 interrupt-controller hardware를 통해.

대부분의 CPU는 두 개의 인터럽트 요청 라인을 갖고 있다. 하나는 nonmaskable 인터럽트로, 복구 불가능한 메모리 오류와 같은 이벤트를 위해 예약되어 있다. 두 번째 인터럽트 라인은 maskable 인터럽트로, 반드시 인터럽트가 발생하지 않아야 하는 중요한 명령어 시퀀스를 실행하기 전에 CPU에 의해 비활성화될 수 있다. 마스커블 인터럽트는 장치 컨트롤러가 서비스를 요청하는 데 사용된다.

벡터 인터럽트 메커니즘의 목적은 단일 인터럽트 핸들러가 가능성이 있는 모든 인터럽트의 원천을 검색하여 어떤 것이 서비스를 필요로 하는지 확인해야 하는 필요성을 줄이는 것이다.  
그러나 실제로 컴퓨터는 인터럽트 벡터의 주소 요소보다 더 많은 장치(그리고 따라서 더 많은 인터럽트 핸들러)를 가지고 있다. 

이 문제를 해결하는 일반적인 방법은 **인터럽트 체이닝(interrupt chaining)**을 사용하는 것이다. 인터럽트 체이닝에서는 인터럽트 벡터의 각 요소가 인터럽트 핸들러 목록의 헤드를 가리키도록 한다.  
인터럽트가 발생하면 해당 목록에 있는 핸들러들이 차례로 호출되며, 요청을 처리할 수 있는 핸들러가 발견될 때까지 실행된다. 이 구조는 거대한 인터럽트 테이블의 높은 오버헤드와 단일 인터럽트 핸들러에 모든 처리를 위임하는 비효율성 사이에서 절충된 방식이다.

## 1.2.2 Storage Structure
CPU는 명령어를 메모리에서만 받아오기 때문에 어떤 프로그램이든 메모리를 통해 실행된다. 일반적인 목적의 컴퓨터들은 프로그램을 rewritable memeory 을 사용해 실행시킨다. 이 메모리는 random-access memory, or RAM or main memory 로 불린다. Main memory는 일반적으로 DRAM(동적 램)이라는 반도체 기술로 구현된다.

컴퓨터는 다른 형태의 메모리도 사용한다. 예를 들어, 컴퓨터의 전원이 켜질 때 가장 먼저 실행되는 프로그램은 부트스트랩(bootstrap) 프로그램이며, 이 프로그램이 운영체제를 로드한다. RAM은 휘발성(volatile) 메모리이므로, 전원이 꺼지거나 손실되면 그 안의 내용이 사라진다. 따라서 RAM에 부트스트랩 프로그램을 저장해 둘 수 없으며, 이를 신뢰할 수도 없다. 이 경우와 그 외의 목적을 위해 컴퓨터는 전기적으로 지워질수 있는, 프로그래밍 될 수 있는 읽기 전용 메모리(EEPROM)과 다른 형태의 firmware(자주 쓰기 작업이 일어나지 않고 휘발적이지 않은)-저장소 를 대신해서 사용한다. 

모든 형태의 메모리는 바이트들로 이루어진 배열을 제공한다. 각 바이트는 그들만의 주소를 가지고 있다.   
상호 작용은 특정 메모리 주소에 대한 로드(load) 또는 스토어(store) 명령어의 연속적인 실행을 통해 이루어진다. 로드(load) 명령어는 메인 메모리에서 바이트 또는 워드를 CPU 내부의 레지스터로 이동시키며, 스토어(store) 명령어는 레지스터의 내용을 메인 메모리에 이동시킨다.  
명시적인 로드 및 스토어 명령어 외에도, CPU는 **프로그램 카운터(program counter)**에 저장된 위치에서 실행할 명령어를 자동으로 메인 메모리에서 로드한다.

폰 노이만(von Neumann) 아키텍처를 사용하는 시스템에서 전형적인 **명령어 실행 사이클(instruction-execution cycle)**은 먼저 메모리에서 명령어를 가져와(instruction fetch) **명령어 레지스터(instruction register)**에 저장하는 것으로 시작된다.

그다음, 명령어를 **디코드**(decode)하고, 필요하면 오퍼랜드(operand)를 메모리에서 가져와 내부 레지스터에 저장할 수도 있다.

이후, 명령어가 오퍼랜드에 대해 실행되며, 실행 결과가 다시 메모리에 저장될 수 있다.

여기서 중요한 점은 **메모리 유닛**(memory unit)은 단순히 메모리 주소의 연속적인 흐름만을 인식할 뿐이라는 것이다. 즉, 이 주소들이 명령어 카운터(instruction counter), 인덱싱(indexing), 간접 주소 지정(indirection), 리터럴 주소(literal addresses) 또는 기타 방법에 의해 생성되었는지, 그리고 해당 주소가 **명령어**(instruction)인지 **데이터**(data)인지에 대한 정보는 알지 못한다. 그런 이유로, 우리는 메모리 주소가 프로그램에 의해 어떻게 생성되는지 무시할 수 있다. 우리는 실행 중인 프로그램에 의해 생성된 메모리 주소의 sequence에만 관심이 있다. 

완전한 저장 시스템을 설계할 때는 앞서 논의한 모든 요소들의 균형을 맞춰야 한다. 즉, 필요한 만큼만 고가의 메모리를 사용하면서도, 최대한 저렴하고 비휘발성(nonvolatile) 저장 장치를 제공할 수 있어야 한다.  
또한, 두 구성 요소 간에 **접근 시간(access time)**이나 **전송 속도(transfer rate)**의 차이가 클 경우, 성능을 향상시키기 위해 **캐시(cache)**를 설치할 수 있다.

## 1.2.3 I/O Structure
운영체제 코드의 상당 부분은 입출력(I/O) 관리에 할애된다. 이는 시스템의 신뢰성(reliability)과 성능(performance)에 있어 I/O의 중요성 때문이며, 동시에 장치들의 특성이 다양하기 때문이기도 하다.

이 섹션의 시작에서 언급했듯이, 범용 컴퓨터 시스템은 여러 장치로 구성되며, 이들은 **공통 버스(common bus)**를 통해 데이터를 교환한다.  
섹션 1.2.1에서 설명된 인터럽트 기반 I/O(interrupt-driven I/O) 방식은 적은 양의 데이터를 전송할 때는 적절하지만, NVS I/O와 같은 대량의 데이터 이동에는 높은 오버헤드를 초래할 수 있다. 이를 해결하기 위해 **직접 메모리 접근(DMA, Direct Memory Access)**이 사용된다.  
DMA에서는 버퍼(buffer), 포인터(pointer), 카운터(counter) 등을 설정한 후, **장치 컨트롤러(device controller)**가 CPU의 개입 없이 장치와 메인 메모리 간에 전체 데이터 블록을 직접 전송한다.  
이 방식에서는 블록당 한 번의 인터럽트만 발생하여 장치 드라이버에게 작업 완료를 알리며, 저속 장치에서처럼 바이트당 인터럽트가 발생하지 않는다. 그리고 장치 컨트롤러가 데이터 전송을 수행하는 동안 CPU는 다른 작업을 수행할 수 있다.

일부 고급(high-end) 시스템에서는 버스 아키텍처(bus architecture) 대신 **스위치 아키텍처(switch architecture)**를 사용한다. 이러한 시스템에서는 여러 구성 요소가 동시에 다른 구성 요소와 통신할 수 있으며, 공유 버스에서 사이클을 놓고 경쟁할 필요가 없다. 이 경우, **DMA(Direct Memory Access)**는 더욱 효과적으로 동작할 수 있다. 그림 1.7은 컴퓨터 시스템의 모든 구성 요소 간 상호작용을 보여준다.