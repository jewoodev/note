---
title : "Open source load testing tool review 정리"
date : 2024-05-11 16:48:00 +09:00
categories : [Test, Load testing tool]
tags : [Load testing tool]
math : true
---

이 글은 아래의 링크 자료를 번역한 글이다. 자신의 상황에 맞는 테스트 툴이 무엇인지 파악하는데 도움이 되길 바라는 의도를 가지고 있다.

[https://grafana.com/blog/2020/03/03/open-source-load-testing-tool-review/](https://grafana.com/blog/2020/03/03/open-source-load-testing-tool-review/)

## 1. 리뷰에 앞서..

The Grinder는 이제 더 이상 개발되어지지 않다고 보여지고 있고 설치하는데 트러블이 있는 것으로 파악이 되며 그렇게 많은 유저 수를 가지고 있지 않다고 판단이 되어 목록에서는 제외했다. 

## 2. 어떤 것이 기준이 되는가?

기본적으로 이 리뷰에서는 다음 두 가지 사항에 중점을 둔다. 

1. **Tool Performance** : 트래픽을 생성하는 도구가 얼마나 효율적이고 측정값은 얼마나 정확한가?
2. **Development UX** : 나와 같은 개발자가 사용하기 얼마나 편리한가?

부하 테스트 자동화는 부하 테스트를 수행하는 개발자에게 점점 더 초점이 맞춰지고 있으며 각 도구를 CI 테스트 제품군에 적절하게 통합할 시간은 없었지만 각 도구의 다운로딩, 설치, 명령줄과 스크립트 실행이라는 지표들을 기준으로 테스트에 얼마나 적합한지 파악하기 위해 노력했다. 

리뷰에는 도구 성능에 대한 확실한 수치가 포함되어 있을 뿐만 아니라 도구의 다양한 측면이나 동작에 대한 매우 주관적인 의견도 많이 포함되어 있다.

## 3. 개발 현황

### 3.1 Artillery

런던의 Shoreditch Ops LTD는 포병을 창설했습니다. 이 사람들은 약간 익명이지만 Artillery가 인기를 끌기 전후에 로드 테스트를 시작한 일종의 스타트업이었던 것으로 기억됩니다. 물론, 나는 결코 일어나지 않은 다른 일들도 기억하므로 누가 알겠습니까? 어쨌든 이 프로젝트는 2015년쯤에 시작된 것으로 보이며 현재 이름을 갖기 전에 Minigun이라는 이름을 갖게 되었습니다.

Artillery는 JavaScript로 작성되었으며 NodeJS를 엔진으로 사용합니다.

### 3.5 JMeter

이건 오래된 거인들의 무리이다. 또한 Apache Software Foundation에서 제공되며 수많은 기능을 갖춘 크고 오래된 Java 앱입니다. 게다가 아직 활발하게 개발 중입니다. 지난 2년 동안 리뷰에서 다른 어떤 도구보다 코드베이스에 대한 커밋이 더 많았습니다.

나는 JMeter가 Gatling과 같은 새로운 도구로 인해 시장 점유율을 서서히 잃어가고 있다고 생각합니다. 그러나 그것이 얼마나 오래 지속되었고 얼마나 많은 추진력을 가지고 있는지를 고려하면 그것이 아직 오랫동안 여기에 있을 것이라는 것은 확실합니다. BlazeMeter와 같이 그 위에 구축된 통합, 추가 기능 및 전체 SaaS 서비스가 너무 많습니다. 게다가 사람들은 그것을 사용하는 방법을 배우는 데 너무 많은 시간을 소비했기 때문에 이 제품은 앞으로 수년 동안 강력하게 사용될 것입니다.

### 3.6 K6

정말 멋진 도구입니다! 아, 앞서 쓴 것처럼 여기에는 다소 편견이 있습니다. 하지만 객관적인 사실은 이렇습니다. k6는 2017년에 출시되었으니 꽤 새롭습니다. Go로 작성되었으며 제가 방금 깨달은 재미있는 점은 Go와 C 사이에 연결이 있다는 것입니다. 리뷰의 도구 세 개는 C로 작성되고 세 개는 Go로 작성되었습니다. 내가 가장 좋아하는 두 가지 언어는 우연인가 패턴인가?!

k6은 원래 SaaS 로드 테스트 서비스인 Load Impact에 의해 구축되었으며 유지 관리됩니다. Load Impact에는 여러 사람이 k6에서 풀타임으로 일하고 있으며 이는 커뮤니티 기여와 함께 개발이 매우 활발하다는 것을 의미합니다. 이 도구가 k6이라고 불리는 이유는 덜 알려져 있지만 여기에 정보를 유출하게 되어 기쁩니다. 오랜 내부 이름 싸움이 결국 대치 상태로 끝났고, 우리는 대부분의 사람들이 싫어하는 "k"로 시작하는 7글자 이름을 갖게 되었습니다. 그래서 이를 "k6"으로 줄여서 문제가 해결된 것 같았습니다. 당신은 일차 세계 문제를 좋아해야합니다!

### 3.11 Wrk

Wrk는 Will Glozer가 C로 작성했습니다. 2012년부터 사용되었기 때문에 완전히 새로운 것은 아니지만 터무니없이 빠르고 효율적이며 일반적으로 매우 견고한 소프트웨어처럼 보이기 때문에 일종의 성능 기준점으로 사용해 왔습니다. 실제로 GitHub에는 23,000개가 넘는 별이 있으므로 다른 많은 도구에 비해 접근성이 떨어지더라도 꽤 큰 사용자 기반을 보유하고 있을 것입니다. (컴파일해야합니다). 불행히도 Wrk는 그렇게 적극적으로 개발되지 않았습니다. 새로운 릴리스는 드뭅니다.

누군가는 Wrk의 로고타입을 디자인해야 한다고 생각합니다. 그럴만한 가치가 있습니다.

## 4. 사용성 검토

저는 개발자이고 일반적으로 포인트 앤 클릭 애플리케이션을 싫어합니다. 명령줄을 사용하고 싶습니다. 나는 또한 스크립팅을 통해 작업을 자동화하는 것을 좋아합니다. 나는 참을성이 없고 일을 끝내고 싶습니다. 나는 나이가 좀 있어서 새로운 기술에 대해 약간 불신하고 전투에서 입증된 제품을 선호한다는 의미입니다. 당신은 다를 수도 있으니 당신은 받아들일 수 있는 것과 나는 받아들일 수 없는 것을 알아내려고 노력하세요. 그 반대도 마찬가지입니다. 그러면 도구에 대한 내 생각을 읽으면서 뭔가를 얻을 수 있을 것입니다.

내가 한 일은 명령줄에서 모든 도구를 수동으로 실행하고 해석된 결과를 stdout으로 인쇄하거나 파일에 저장하는 것입니다. 그런 다음 결과를 자동으로 추출하고 대조하는 쉘 스크립트를 만들었습니다.

도구를 사용하면서 각 도구에 대한 통찰력을 얻었고, 내 특정 사용 사례에 대한 강점과 약점이 무엇인지 알게 되었습니다. 제가 찾고 있는 것이 자동화된 로드 테스트를 설정할 때 찾고 있는 것과 유사하다고 생각합니다. 그러나 각 도구를 일부 CI 테스트 제품군에 실제로 통합하지 않았기 때문에 모든 측면을 고려하지 않을 수도 있습니다. 단지 면책 조항입니다.

또한 도구의 성능이 유용성 검토에 영향을 미쳤다는 점에 유의하세요. 생성하고 싶은 트래픽을 생성하기가 어렵거나 도구의 측정을 신뢰할 수 없다고 생각되면 사용성 검토에 이를 반영합니다. 그러나 성능에 대한 세부 정보를 보려면 성능 벤치마크까지 아래로 스크롤해야 합니다.

### 4.1 RPS

이 블로그 기사 전체에서 RPS라는 용어가 자유롭게 사용되는 것을 볼 수 있습니다. 이 약어는 부하 테스트 도구가 생성하는 트래픽 양을 측정하는 "초당 요청 수"를 나타냅니다.

### 4.2 VU

이것은 꽤 많이 사용되는 또 다른 용어입니다. "가상 사용자"의 약어인 (로드) 테스트 약어입니다. 가상 사용자는 시뮬레이션된 인간/브라우저입니다. 부하 테스트에서 VU는 일반적으로 HTTP 요청을 독립적으로 보내는 동시 실행 스레드/컨텍스트를 의미하므로 부하 테스트에서 많은 동시 사용자를 시뮬레이션할 수 있습니다.

### 4.3 Scriptable tools vs non-scriptable ones

저는 스크립팅을 지원하는 도구와 그렇지 않은 도구 모두에 대해 제가 가장 좋아하는 도구 목록을 만들기로 결정했습니다. 그 이유는 스크립팅이 필요한지 여부는 사용 사례에 따라 많이 달라지며 여기서 언급할 가치가 있는 스크립팅을 지원하지 않는 몇 가지 매우 좋은 도구가 있기 때문입니다.

#### 4.3.1 What’s the difference between a scriptable and a non-scriptable tool?

스크립트 가능 도구는 Python, JavaScript, Scala 또는 Lua 등의 테스트 사례를 작성하는 데 사용하는 실제 스크립트 언어를 지원합니다. 이는 테스트를 설계할 때 최대의 유연성과 성능을 얻을 수 있음을 의미합니다. 고급 논리를 사용하여 테스트에서 어떤 일이 발생하는지 확인할 수 있습니다. 추가 기능을 위해 라이브러리를 가져올 수 있습니다. 코드를 여러 파일로 분할할 수 있는 경우가 많습니다. 실제로 이는 작업을 수행하는 "개발자 방식"입니다.

반면, 스크립팅이 불가능한 도구는 특정 스크립팅 API를 배울 필요가 없으므로 시작하기가 더 간단한 경우가 많습니다. 또한 스크립트 스레드에 대한 스크립팅 언어 런타임 및 실행 컨텍스트가 필요하지 않기 때문에 스크립팅 가능한 도구보다 적은 리소스를 소비하는 경향이 있습니다. 따라서 (일반적으로) 더 빠르고 메모리를 덜 소비합니다. 부정적인 측면은 그들이 할 수 있는 일이 더 제한적이라는 것입니다.

### 4.4 The top non-scriptable tools

#### 4.4.3 Wrk

#### ![img](https://grafana.com/media/blog/k6/wrk-run.png)

Wrk는 약간 구식일 수 있고 요즘에는 새로운 기능이 많이 제공되지 않지만 정말 !#&%€ 견고한 코드 조각입니다. 항상 예상한 대로 작동하며 속도/효율성 측면에서 다른 모든 도구를 중심으로 순환합니다. Wrk를 사용하면 동일한 하드웨어에서 k6을 사용할 때보다 5배 많은 트래픽을 생성할 수 있습니다. 그것이 k6의 소리를 나쁘게 만든다고 생각한다면 다시 생각해보세요. k6가 느린 것이 아니라 Wrk가 너무 빠르다는 것입니다. 다른 도구와 비교하면 Wrk는 Gatling보다 10배 빠르고 Locust보다 15~20배 빠르며 Artillery보다 100배 이상 빠릅니다.

여러 도구를 사용하면 VU 스레드가 Wrk에서 허용하는 것보다 훨씬 더 정교한 스크립트 코드를 실행할 수 있으므로 비교는 약간 불공평합니다. Wrk는 스크립팅을 전혀 제공하지 않는다고 생각하겠지만 실제로는 VU 스레드에서 Lua 코드를 실행할 수 있으며 이론적으로는 꽤 복잡한 테스트 코드를 생성할 수 있습니다. 그러나 실제로 Wrk 스크립팅 API는 콜백 기반이므로 복잡한 테스트 논리를 작성하는 데 전혀 적합하지 않습니다. 그러나 그것은 또한 매우 빠릅니다. 이번에는 Wrk를 테스트할 때 Lua 코드를 실행하지 않았습니다. 대신 단일 URL 테스트 모드를 사용했지만 이전 테스트에서는 Lua 코드를 실행할 때 Wrk 성능에 최소한의 영향만 미치는 것으로 나타났습니다.

그러나 빠르고 정확하게 측정하는 것이 Wrk의 모든 기능입니다. HTTP/2 지원, 고정 요청 속도 모드, 출력 옵션, CI 설정에서 통과/실패 결과를 생성하는 간단한 방법 등이 없습니다. 간단히 말해서 기능이 매우 희박합니다.

##### Wrk help output

![A screenshot of the Wrk help output](https://grafana.com/media/blog/k6/wrk-help.png)

##### Wrk summary

Wrk is included among the top non-scriptable tools because if your only goal is to generate a truckload of simple traffic against a site, there is no tool that does it more efficiently. It will also give you accurate measurements of transaction response times, which is something many other tools fail at when they’re being forced to generate a lot of traffic.

### 4.5 The top scriptable tools

#### 4.5.2 k6

![A screenshot of a k6 runtime](https://grafana.com/media/blog/k6/k6-run.png)

제가 k6의 창작에 참여했던 만큼, 그 프로젝트가 내린 선택이 마음에 드는 것도 이상하지 않습니다. k6의 기본 아이디어는 현대 개발자를 위한 고품질 로드 테스트 도구를 만드는 것이었습니다. 이를 통해 테스트를 순수 코드로 작성할 수 있고 간단하고 일관된 명령줄 UX가 있으며 유용한 결과 출력 옵션이 있고 충분한 성능을 제공합니다. 저는 이러한 모든 목표가 거의 달성되었다고 생각하며, 이로 인해 k6는 부하 테스트 도구에 대한 매우 매력적인 선택이 됩니다. 특히 나 같은 개발자에게는 더욱 그렇습니다.

k6은 일반 JavaScript로 스크립팅이 가능하며 제가 테스트한 모든 도구 중에서 가장 좋은 스크립팅 API를 가지고 있습니다. 일반적인 작업을 쉽게 수행하고, 예상대로 동작하는지 테스트하고, 자동화된 테스트를 위한 통과/실패 동작을 제어할 수 있게 해주는 이 API입니다. 매우 간단한 k6 스크립트는 다음과 같습니다.

```javascript
import http from 'k6/http';
import { check } from 'k6';

export default function () {
  const res = http.get('http://192.168.0.121:8080/');
  check(res, {
    'is status 200': (r) => r.status === 200,
  });
}
```

위 스크립트는 각 VU가 HTTP 트랜잭션을 생성하도록 한 다음 응답 코드가 200인지 확인합니다. 이와 같은 검사 상태는 stdout에 인쇄되며, 검사 중 상당수가 실패할 경우 테스트에 실패하도록 임계값을 설정할 수 있습니다. k6 스크립팅 API를 사용하면 자동화된 성능 테스트 작성이 매우 좋은 경험이 됩니다.

k6 명령줄 인터페이스는 간단하고 직관적이며 일관성이 있어 현대적인 느낌을 줍니다. k6은 이 리뷰에서 가장 빠른 도구 중 하나입니다. 모든 기본 프로토콜(HTTP 1/2/Websocket)을 지원합니다. 다양한 출력 옵션(text, JSON, InfluxDB, StatsD, Datadog, Kafka)이 있습니다. k6는 HAR 파일을 k6 스크립트로 변환할 수 있고 주요 브라우저는 세션을 기록하고 HAR 파일로 저장할 수 있으므로 브라우저에서 트래픽을 기록하는 것은 매우 쉽습니다. 또한 Postman 컬렉션을 k6 스크립트 코드로 변환하는 옵션도 있습니다. 아, 그리고 문서는 전반적으로 훌륭합니다. (방금 문서 작업을 하는 사람과 이야기를 나눴는데 그 사람이 현재 상태에 불만족스러워서 정말 좋은 것 같아요. 제품 개발자가 만족하면 제품이 정체됩니다. ).

그렇다면 k6에는 무엇이 부족한가? 글쎄요, 로드 생성 분배는 포함되어 있지 않으므로 대규모 테스트를 실행하려면 프리미엄 SaaS 버전(로드 생성이 분산된 버전)을 구입해야 합니다. 반면에 성능은 어쨌든 단일 물리적 시스템에서 로드 생성 용량이 부족할 가능성이 거의 없음을 의미합니다. 그런 일에 관심이 있다면 어떤 종류의 웹 UI도 제공되지 않습니다. 난 아니다.	

사람들이 기대할 수 있지만 k6에는 없는 것 중 하나는 NodeJS 호환성입니다. 많은(아마도 대부분?) NodeJS 라이브러리는 k6 스크립트에서 사용할 수 없습니다. NodeJS 라이브러리를 사용해야 한다면 Artillery가 유일한 안전한 선택일 수 있습니다. (오 안돼!)

그렇지 않으면, 제가 k6에 대해 마음에 들지 않는 유일한 점은 테스트를 JavaScript로 스크립트해야 한다는 사실입니다! JS는 제가 가장 좋아하는 언어가 아니며, 개인적으로 저는 Python이나 Lua를 사용하는 것을 선호했습니다. 후자는 Load Impact가 로드 테스트를 스크립팅하기 위해 수년 동안 사용해온 스크립팅 언어이며 매우 리소스 효율적입니다. 그러나 시장 침투 측면에서 Lua는 초파리이고 JS는 코끼리이므로 Lua 대신 JS를 선택하는 것이 현명했습니다. 그리고 솔직히 말해서 스크립팅이 XML(또는 Java)로 이루어지지 않는 한 만족스럽습니다.

### 4.6 The rest of the tools

#### 4.6.2 Artillery

![Artillery runtime screenshot](https://grafana.com/media/blog/k6/artillery-run.png)

Artillery는 매우 느리고 리소스를 많이 소모하며 아마도 활발하게 개발되지 않은 오픈 소스 로드 테스트 도구입니다. 별로 기분 좋은 요약은 아니지만 계속 읽어보세요.

NodeJS를 엔진으로 사용하여 JavaScript로 작성되었습니다. NodeJS를 기반으로 구축할 때 좋은 점은 NodeJS 호환성입니다. Artillery는 Javascript로 스크립트 가능하며 일반 NodeJS 라이브러리를 사용할 수 있습니다. 이는 k6이 일반 JavaScript에서도 스크립트 가능함에도 불구하고 k6에서는 할 수 없는 일입니다. 그러나 NodeJS 앱의 나쁜 점은 성능입니다. 2017년 벤치마크 테스트에서 Artillery는 Locust에 이어 두 번째로 나쁜 성능을 발휘하는 것으로 나타났습니다. 그다지 인상적이지 않은 RPS 수치와 전혀 정확하지 않은 응답 시간 측정값을 생성하기 위해 엄청난 양의 CPU와 메모리를 사용하고 있었습니다.

2017년 이후 이곳의 상황이 크게 변하지 않았다는 사실이 안타깝습니다. 오히려 오늘날 Artillery은 조금 더 느린 것 같습니다.

2017년에 Artillery는 단일 CPU 코어에서 실행되는 Locust보다 두 배 많은 트래픽을 생성할 수 있습니다. 현재 Artillery는 Locust가 생성할 수 있는 트래픽의 1/3만 생성할 수 있습니다. 두 도구 모두 마찬가지로 단일 CPU 코어를 사용하도록 제한되어 있습니다. 로커스트의 성능이 좋아진 것도 있지만 변화폭이 생각보다 커서 Artillery 성능도 떨어졌을 게 확실합니다. 이 이론을 뒷받침하는 또 다른 데이터 포인트는 Artillery 대 Tsung입니다. 2017년 Tsung은 포병보다 10배 더 빨랐습니다. 오늘날 Tsung은 30배 더 빠릅니다. 나는 Tsung의 성능이 전혀 변하지 않았다고 믿습니다. 이는 포병이 예전보다 훨씬 느리다는 것을 의미합니다(그리고 그 당시에도 정확히 빠르지는 않았습니다).

Artillery의 성능은 확실히 문제이고, 더욱 악화되는 요인은 오픈 소스 Artillery에는 여전히 어떤 종류의 분산 로드 생성 지원도 없기 때문에 프리미엄 SaaS 제품을 구매하지 않는 한 성능이 매우 낮은 솔루션에 갇혀 있다는 것입니다.

Artillery의 성능은 확실히 문제이고, 더욱 악화되는 요인은 오픈 소스 Artillery에는 여전히 어떤 종류의 분산 로드 생성 지원도 없기 때문에 프리미엄 SaaS 제품을 구매하지 않는 한 성능이 매우 낮은 솔루션에 갇혀 있다는 것입니다. .

포병.io 사이트에서는 Artillery 오픈 소스와 Artillery Pro 사이에 어떤 차이점이 있는지 명확하지 않지만 Artillery Pro에 대해서만 변경 로그가 있는 것으로 보이며 GitHub 레포를 보면 Artillery 오픈 소스의 버전 번호는 1.6입니다. Changelog에 따르면 Pro는 2.2.0이고 Pro는 .0입니다. 오픈 소스 Artillery의 커밋 메시지를 살펴보면 대부분 버그 수정이 있었고 2년 이상 동안 커밋이 너무 많지 않은 것 같습니다.

Artillery 팀은 Artillery 오픈 소스와 프리미엄 제품인 Artillery Pro 간의 차이점을 문서화하는 데 더 많은 노력을 기울여야 하며, 오픈 소스 제품에 대한 의도에 대해서도 작성해야 합니다. 서서히 단종되는 건가요? 확실히 그렇게 보입니다.

성능과 관련하여 주목해야 할 또 다른 점은 요즘 Artillery는 CPU 사용량이 (단일 코어의) 80%를 초과할 때마다 "높은 CPU" 경고를 인쇄하며 "성능 저하"를 방지하기 위해 해당 양을 절대 초과하지 않는 것이 좋습니다. 이러한 경고를 피하기 위해 CPU 사용량을 약 80%로 유지하면 Artillery는 훨씬 적은 트래픽을 생성합니다. 이는 Locust가 수행할 수 있는 초당 요청 수의 약 1/8입니다. 경고 메시지를 무시하고 포병이 코어 하나를 100% 사용하도록 하면 RPS가 Locust가 수행할 수 있는 것의 1/3로 증가합니다. 그러나 꽤 큰 측정 오류가 발생했습니다.

모든 성능 문제를 제쳐두고 Artillery에는 몇 가지 좋은 측면이 있습니다. 명령줄에서 사용하기 쉽고, 간단하고 간결한 YAML 기반 구성 형식을 가지고 있으며, 합격/불합격 결과를 생성하는 플러그인이 있고 결과를 JSON 형식으로 출력하므로 CI/자동화에 매우 적합합니다. 그리고 앞서 언급한 것처럼, 가져오기가 간편하고 엄청난 양의 기능을 제공하는 일반 NodeJS 라이브러리를 사용할 수 있습니다. 그러나 도구가 포병과 같은 방식으로 작동하는 경우에는 이 모든 것이 나에게 중요하지 않습니다. Artillery 사용을 고려할 수 있는 유일한 상황은 테스트 사례가 k6에서는 사용할 수 없지만 Artillery에서는 사용할 수 있는 일부 NodeJS 라이브러리에 의존해야 하는 경우입니다.

##### Artillery summary

이미 NodeJS에 영혼을 팔았을 경우에만 사용하십시오(즉, NodeJS 라이브러리를 사용해야 하는 경우).

### 4.7 JMeter

![JMeter runtime screenshot](https://grafana.com/media/blog/k6/jmeter-run.png)

여기 800파운드짜리 고릴라가 있습니다. JMeter는 대부분의 다른 도구에 비해 거대한 짐승입니다. 이 리뷰의 다른 도구보다 오래되었으며 더 큰 기능 세트와 더 많은 통합, 추가 기능 및 플러그인을 획득했습니다. 오랫동안 오픈 소스 부하 테스트 도구의 "왕"이었으며 아마도 지금도 그럴 것입니다.

예전에는 사람들이 HP Loadrunner 라이센스를 위해 터무니없는 금액을 지불하거나 일부 Loadrunner-wannabe 독점 도구 라이센스를 위해 상당한 금액을 지불하거나 JMeter를 사용하기 위해 전혀 비용을 지불하지 않는 것 중에서 선택할 수 있었습니다. 글쎄요, ApacheBench나 OpenSTA 또는 기타 잘 알려진 무료 솔루션을 사용할 수 있는 옵션도 있었지만 심각한 로드 테스트를 수행하고 싶다면 JMeter가 실제로 비용이 들지 않는 유일한 대안이었습니다.

따라서 JMeter 사용자 기반은 계속해서 성장했고 JMeter의 개발도 성장했습니다. 15년 정도 지난 지금, JMeter는 다른 부하 테스트 도구보다 오랫동안 대규모 커뮤니티에서 적극적으로 개발되었으므로 다른 도구보다 더 많은 기능을 가지고 있다는 것도 이상하지 않습니다.

원래 15~20년 전의 오래된 독점 로드 테스트 소프트웨어에 대한 대안으로 구축되었으므로 해당 애플리케이션과 동일한 대상을 수용하도록 설계되었습니다. 즉, 계획하는 데 오랜 시간이 걸리고 실행하는 데 오랜 시간이 걸리며 결과를 분석하는 데 더 오랜 시간이 걸리는 복잡한 대규모 통합 로드 테스트를 실행하는 로드 테스트 전문가가 사용하도록 설계되었습니다.

많은 수동 작업과 매우 구체적인 부하 테스트 도메인 지식이 필요한 테스트입니다. 이는 JMeter가 처음부터 자동화된 테스트 및 개발자 사용을 위해 구축되지 않았음을 의미하며, 이는 오늘날 JMeter를 사용할 때 분명히 느낄 수 있습니다. 개발자를 위한 도구가 아닌 전문 테스터를 위한 도구입니다. 명령줄 사용이 어색하기 때문에 자동화된 테스트에는 적합하지 않습니다. 기본 결과 출력 옵션은 제한되어 있습니다. 많은 리소스를 사용합니다. 실제 스크립팅 기능이 없습니다. 그리고 XML 구성 내부에 논리를 삽입하는 기능만 일부 지원합니다.

이것이 아마도 JMeter가 Gatling과 같은 최신 도구로 시장 점유율을 잃고 있는 이유일 것입니다. Gatling은 JMeter와 공통점이 많고 스크립팅 및 자동화에 대한 더 나은 지원을 통해 보다 현대적인 도구를 사용하고 싶지만 여전히 원하는 조직에 매력적인 업그레이드 경로를 제공합니다. 도구를 Java 기반으로 유지하세요.

##### JMeter summary

로드 테스트를 막 시작한 경우 오늘 JMeter를 선택하는 가장 큰 이유는 다음과 같습니다.

JMeter만이 지원하는 다양한 프로토콜/앱을 테스트해야 했습니다.
Java 중심 조직이고 가장 일반적인 Java 기반 로드 테스트 도구를 사용하려는 경우, 또는
가리키고 클릭하여 작업을 수행할 수 있는 GUI 로드 테스트 도구가 필요합니다.
이들 중 어느 것도 사실이 아니라면 Gatling(여러 면에서 JMeter와 상당히 유사함), k6 또는 Locust가 더 나은 서비스를 제공한다고 생각합니다. 또는 프로그래밍 가능성/스크립팅(테스트를 코드로 작성)에 그다지 관심이 없다면 Vegeta를 살펴볼 수 있습니다.

대상으로는 16G RAM이 장착된 4Ghz i7 iMac을 사용했습니다. 나는 작업 기계와 동일한 기계를 사용하여 터미널 창을 실행하고 브라우저에 Google 스프레드시트를 열었지만 테스트가 실행되는 동안 요구 사항이 발생하지 않는지 확인했습니다. 이 기계에는 하이퍼스레딩(8개 항목을 병렬로 실행할 수 있음)을 갖춘 4개의 매우 빠른 코어가 있으므로 여유 용량이 있어야 하지만 안전을 확보하기 위해 모든 테스트를 서로 다른 시점에서 여러 번 반복했습니다. 결과는 다소 안정적입니다.

## 5. What I’ve tried to find out

### 5.1 Max traffic generation capability

이 실험 설정에서 각 도구는 초당 몇 개의 요청을 생성할 수 있습니까? 여기서는 사용 가능한 대부분의 매개변수를 사용하여 작업을 시도했지만 주로 동시성(도구가 사용하는 스레드 수 및 TCP 연결 수)과 HTTP 연결 유지 활성화, 도구에서 많은 CPU가 필요한 작업 비활성화(HTML 구문 분석) 등의 작업을 시도했습니다. . 목표는 어떤 비용을 치르더라도 각 도구에서 초당 최대한 많은 요청을 처리하는 것이었습니다!!

아이디어는 원시 트래픽 생성과 관련하여 도구가 얼마나 효율적인지 보여주는 각 도구에 대한 일종의 기준을 얻는 것입니다.

### 5.2 Memory usage per VU

일부 도구는 메모리를 많이 사용하며 때로는 메모리 사용량이 VU 측면에서 테스트 크기에 따라 달라집니다. VU당 메모리 사용량이 높으면 도구를 사용하여 대규모 테스트를 실행하는 데 방해가 될 수 있으므로 측정하기에 흥미로운 성능 지표라고 생각합니다.

### 5.3 Memory usage per request

일부 도구는 부하 테스트 전반에 걸쳐 많은 통계를 수집합니다. 주로 HTTP 요청이 이루어질 때 다양한 트랜잭션 시간 측정항목을 저장하는 것이 일반적입니다. 정확히 무엇을 저장하고 어떻게 저장하는지에 따라 이는 많은 양의 메모리를 소비하고 집중적이거나 장기 실행되는 테스트에 문제가 될 수 있습니다.

### 5.4 Measurement accuracy

모든 도구는 부하 테스트 중에 트랜잭션 응답 시간을 측정하고 보고합니다. 이러한 측정에는 여러 가지 이유로 항상 어느 정도의 부정확성이 있지만, 특히 부하 생성기 자체가 약간의 작업을 수행하는 경우 응답 시간 측정에 상당한 양의 추가 지연이 추가되는 것이 일반적입니다. 부하 테스트 도구에서 보고한 응답 시간 측정값을 신뢰할 수 있는 경우와 신뢰할 수 없는 경우를 아는 것이 유용합니다. 저는 다양한 도구 각각에 대해 이를 알아내려고 노력했습니다.

## 6. Let's see what I’ve tried to find out

### 6.1 Max traffic generation capability

다음은 실제로 모든 정지 작업을 수행했을 때 각 도구에서 얻을 수 있는 최대 RPS 수치와 메모리 사용량을 보여주는 차트입니다.

![A chart comparing the maximum traffic generation and the memory usage of the best open source load testing tools.](https://grafana.com/media/blog/k6/RPSvMemory_all.png)

여기서 Wrk가 실제 경쟁 상대가 아니라는 것은 매우 분명합니다. 트래픽 생성에 있어서는 엄청난 양의 HTTP 요청을 원하는 경우 Wrk를 다운로드(및 컴파일)합니다. 당신은 불쾌하지 않을 것입니다!

그러나 Wrk는 훌륭한 요청 생성기이지만 확실히 모든 용도에 완벽하지는 않으므로 다른 도구에 어떤 문제가 있는지 알아보는 것이 흥미로울 것입니다. 더 나은 규모를 얻기 위해 차트에서 Wrk를 제거해 보겠습니다.

![A chart comparing the maximum traffic generation and the memory usage of the best open source load testing tools excepts Wrk](https://grafana.com/media/blog/k6/RPSvMemory.png)

이러한 결과를 논의하기 전에 가능한 가장 높은 RPS 수치를 생성하기 위해 세 가지 도구가 기본이 아닌 모드에서 실행되었다는 점을 언급하고 싶습니다.

#### 6.1.1 Artillery

Artillery는 전체 CPU 코어를 사용하게 할 만큼 높은 동시성 설정으로 실행되었습니다. 이는 Artillery 개발자가 권장하지 않으며 Artillery에서 높은 CPU 경고가 표시되는 결과입니다. 전체 CPU 코어를 사용하면 CPU를 ~80%로 실행할 때 100RPS가 조금 넘는 수준에서 100% CPU를 사용할 때 300RPS로 요청 속도가 크게 증가한다는 사실을 발견했습니다. 물론 RPS 수치는 여전히 엄청나게 낮으며 응답 시간 정확도 테스트에서도 볼 수 있듯이 포병이 하나의 CPU 코어를 모두 사용하도록 만들어지면 응답 시간 측정을 거의 사용할 수 없을 가능성이 높습니다.

#### 6.1.2 k6

k6은 최신 JavaScript 기능을 비활성화하는 --compatibility-mode=base 명령줄 옵션으로 실행되어 스크립팅을 위해 이전 ES5를 사용하게 되었습니다. 결과적으로 메모리 사용량이 ~50% 감소하고 일반 속도가 ~10% 향상됩니다. 이는 최대 RPS 속도가 ~10k에서 ~11k로 증가함을 의미합니다. 하지만 큰 차이는 아니며, 메모리 문제가 없다면 k6을 실행할 때 이 모드를 사용할 가치가 없다고 말하고 싶습니다.

#### 6.1.3 What has changed since 2017?

2017년에 대부분의 도구를 테스트했고 지금도 성능이 거의 동일할 것으로 예상했기 때문에 이 결과가 처음에는 약간 혼란스러웠다고 말하고 싶습니다. 물론 절대 RPS 수치는 이전 테스트와 비교할 수 없습니다. 그 이유는 당시에 다른 테스트 설정을 사용했기 때문입니다. 하지만 도구 간의 관계는 거의 동일하게 유지될 것으로 예상했습니다. 예를 들어, 저는 JMeter가 여전히 가장 빠른 도구 중 하나일 것이라고 생각했고, 단일 CPU 코어에서 실행될 때 Artillery가 Locust보다 여전히 더 빠를 것이라고 생각했습니다.

#### 6.1.4 JMeter is slower!

글쎄, 보시다시피 JMeter 성능은 이제 꽤 평균적인 것 같습니다. 내 테스트에 따르면 JMeter의 성능은 버전 2.3과 지금 테스트한 버전인 5.2.1 사이에서 약 50% 정도 떨어진 것 같습니다. JVM 문제일 수도 있습니다. OpenJDK 11.0.5 및 Oracle Java 13.0.1로 테스트했는데 둘 다 거의 동일하게 수행되었으므로 JVM 속도가 느려서 그럴 가능성은 거의 없습니다. 또한 JVM이 할당할 수 있는 메모리 양을 결정하는 -Xms 및 -Xmx 매개변수를 높여 보았지만 성능에는 영향을 미치지 않았습니다.

#### 6.1.5 Artillery은 이제 빙하처럼 느리고 Locust는 거의 괜찮습니다!

Artillery의 경우에도 2년 전보다 지금이 50% 정도 느려진 것 같습니다. 즉, 제가 그 도구가 얼마나 느리다고 끝없이 징징대던 2년 전 Locust만큼 느려졌습니다. 그리고 로커스트? 2017년 이후 성능이 크게 향상된 단일 도구입니다. 이제 새로운 FastHttpLocust HTTP 라이브러리 덕분에 당시보다 약 3배 더 빠릅니다. 이는 이전 HttpLocust 라이브러리(매우 사용자 친화적인 Python 요청 라이브러리를 기반으로 함)에서 제공하는 약간의 기능이 손실됨을 의미하지만 Locust의 성능 향상은 정말 좋았다고 생각합니다.

#### 6.1.6 Summarizing traffic generation capability

나머지 도구는 2017년과 거의 동일한 성능을 제공합니다.

엄청난 양의 트래픽을 생성해야 하는 경우 차트 왼쪽에 있는 도구 중 하나를 사용하는 것이 더 효율적일 수 있지만 대부분의 경우에는 그것만으로도 충분할 것입니다. 초당 2,000개의 요청을 생성할 수 있으며 이는 Gatling이나 Siege 또는 분산 Locust 설정에서 수행할 수 있는 작업입니다.

하지만 마조히스트가 아니거나 추가 도전을 원하지 않는 한 포병이나 드릴을 사용하는 것을 권장하지 않습니다. 로드 생성기에서 CPU를 모두 사용해야 하기 때문에 측정이 왜곡되면 충분한 트래픽을 생성하는 것이 까다로울 뿐만 아니라 결과(적어도 포병의 경우)를 해석하는 것도 까다롭습니다.

### 6.2 Memory usage

