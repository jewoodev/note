# 3. start()와 run()
쓰레드를 실행시키고 싶으면 start()를 호출해야 한다. run()이 아닌 start()를 호출해야 하는 이유는 둘의 차이와 스레드가 실행되는 과정에 대해 알아야 이해할 수 있다.

main메서드에서 run()을 호출하는 건 생성된 스레드를 실행시키는 게 아니라 단순히 클래스에 선언된 메서드를 호출하는 것일 뿐이다.

반면 start()는 새로운 스레드가 작업을 실행하는데 필요한 호출스택을 생성한 다음 run()을 호출해서, 생성된 호출스택에 run()이 첫번째로 올라가게 한다.

모든 스레드는 독립적인 작업을 수행하기 위해 자신만의 호출스택을 필요로 하기 때문에 새로운 스레드를 생성하고 실행시킬 때마다 새로운 호출스택이 생성되고 스레드가 종료될 때 스레드의 호출스택도 함께 소멸된다.

그렇게 메인 메서드에서 다른 스레드를 start시키면 해당 프로세스의 스레드는 두 개가 되고, 스레드가 두 개 이상일 땐 호출스택의 최상위에 있는 메서드일지라도 대기상태에 있을 수 있다.

### main스레드
main메서드의 작업을 수행하는 것도 스레드이며, 그 스레드를 main스레드라고 한다. 

프로그램을 실행하면 기본적으로 하나의 스레드(일꾼)를 생성하고 그 스레드가 main메서드를 호출해서 작업이 수행되도록 한다.

main메서드의 수행이 마무리되면 프로그램이 종료될까? 항상 그렇지는 않다. main메서드 수행이 마무리되었다고 하더라도 다른 스레드가 아직 작업을 마치지 않은 상태라면 프로그램은 종료되지 않는다.



# 4. 싱글 스레드와 멀티 스레드
스레드 성능 측정을 위해 반복작업 수행시간을 측정해보면 결과가 매번 다를 수 있다.  
그 이유는 실행 중인 프로세스가 OS의 프로세스 스케줄러의 영향을 받기 때문이다. JVM의 스레드 스케줄러에 의해 어떤 스레드가 얼마동안 실행될 것인지 결정되는 것과 같이 프로세스도 프로세스 스케줄러에 의해 실행순서와 실행시간이 결정되기 때문에 매 순간 상황에 따라 프로세스에게 할당되는 실행시간이 일정하지 않다. 이 사실은 스레드에게 할당되는 시간에 영향을 끼치기 때문에 그 또한 일정하지 않게 된다.  
이러한 이유로 스레드가 불확실성을 가지고 있다는 걸 염두해 두어야 한다.

자바가 OS(플랫폼) 독립적이라고 하지만 실제로는 OS 종속적인 부분이 몇 가지 있는데 스레드가 그 중 하나이다.



# 5. 스레드 우선순위
스레드는 우선순위라는 속성을 가지고 있는데, 이 우선순위 값에 따라 스레드가 얻는 실행시간이 달라진다.  
따라서 스레드가 수행하는 작업의 중요도에 따라서 우선순위를 지정하고, 특정 스레드가 더 많은 시간동안 실행되도록 할 수 있다.

### 스레드의 우선순위 지정하기
'스레드의 우선순위'와 관련된 메서드와 상수는 다음과 같다.
```java
void setPriority(int Priority) 
int getPriority()

public static final int MAX_PRIORITY = 10
public static final int MIN_PRIORITY = 1
public static final int NORM_PRIORITY = 5
```

한 가지 중요한 점은 '스레드의 우선순위는 스레드를 생성한 스레드로부터 상속받는다.' 라는 것이다.  
main메서드를 수행하는 스레드는 우선순위가 5이므로 main메서드 내에서 생성하는 스레드의 우선순위는 자동적으로 5가 된다.

우선순위는 스레드가 실행되기 전에만 변경되어 적용될 수 있다는 점을 기억하자.



# 7. 데몬 스레드
다른 일반 스레드의 작업을 돕는 보조적인 역할의 스레드이다. 일반 스레드가 모두 종료되면 데몬 스레드는 강제적으로 자동 종료되는데, 그 이유는 데몬 스레드의 역할이 일반 스레드를 보조하는 것이기 때문이다.  
데몬 스레드의 예로 가비지 컬렉터, 워드프로세서의 자동저장, 화면 자동갱신 등이 있다.

데몬 스레드는 무한루프와 조건문을 이용해 실행 후 대기하다가 특정 조건이 만족되면 작업을 수행하고 다시 대기하도록 작성한다.  
데몬 스레드는 일반 스레드의 작성방법과 실행방법이 같으며 다만 스레드를 생성한 다음 실행하기 전에 setDaemon(true)를 호출하기만 하면 된다.  
그런데 데몬 스레드가 생성한 스레드는 자동적으로 데몬 스레드가 된다.



# 9. 스레드의 동기화
## 9.3 Lock과 Condition을 이용한 동기화
스레드 동기화를 하는 방법 중에 가장 오래된 방법은 'synchronized 블럭'을 활용하는 방법이다. 이 방법은 자동으로 lock 잠금/풀림이 처리(예외가 발생해도 풀림)되어 편리하지만 같은 메서드 내에서만 lock을 걸 수 있는 한계점이 있다.

JDK1.5부터 추가된 'java.util.concurrent.locks' 패키지의 lock 클래스들을 사용하면 그런 한계점을 해결할 수 있다. lock 클래스의 종류는 3가지이다.

- `ReentrantLock`: 재진입이 가능한 lock. 가장 일반적인 베타 lock
- `ReentrantReadWriteLock`: 읽기에는 공유적이고, 쓰기에는 배타적인 lock
- `StampedLock`: `ReentrantReadWriteLock`에 낙관적인 lock의 기능을 추가

ReentrantLock은 가장 일반적인 lock으로, 특정 조건에서 lock을 풀고 나중에 다시 lock을 얻어서 임계영역 안의 작업을 수행할 수 있다. 그래서 '재진입할 수 있는' 이란 뜻을 가진 단어로 이름붙여졌다.

ReentrantReadWriteLock은 읽기와 쓰기를 위한 lock을 각각 제공한다. ReentrantLock은 배타적인 lock이라서 무조건 lock이 있어야만 임계영역의 코드를 수행할 수 있지만 ReentrantReadWriteLock은 읽기 lock이 걸려있어도 다른 스레드가 읽기 lock을 중복해서 걸 수 있어 동시에 읽기를 수행할 수 있다. 그렇다고 쓰기 lock까지 중복해서 걸 수 있는 lock은 아니다. 읽기 lock이 걸린 상태에서 쓰기 lock을 거는 것도 허용되지 않으며, 반대의 경우도 마찬가지다.

StampedLock은 lock을 걸거나 해지할 때 '스탬프(long타입의 정수값)'를 사용하며, 읽기와 쓰기를 위한 lock 외에 '낙관적 읽기 lock(optimistic reading lock)'이 추가된 lock이다. 읽기 lock이 걸려있는 상태에서 쓰기 lock을 걸려면 읽기 lock이 풀릴 때까지 기다려야 하는 ReentrantReadWriteLock와 다르게 '낙관적 읽기 lock'은 쓰기 lock에 의해 바로 풀린다. 낙관적 읽기에 실패하면, 읽기 lock을 얻어서 다시 읽어 와야 한다. 무조건 읽기 lock을 걸지 않고, 쓰기와 읽기가 충돌할 때만 쓰기가 끝난 후에 읽기 lock을 거는 것이다.

다음의 코드는 가장 일반적인 StampedLock을 이용한 낙관적 읽기의 예이다.
```java
int getBalance() {
    long stamp = lock.tryOptimisticRead(); // 낙관적 읽기 lock을 건다.
    int curBalance = this.balance; // 공유 데이터인 balance를 읽어온다.
    
    if (!lock.validate(stamp)) { // 쓰기 lock에 의해 낙관적 읽기 lock이 풀렸는지 확인
        stamp = lock.readLock(); // lock이 풀렸으면, 읽기 lock을 얻으려고 기다린다.
        
        try {
            curBalance = this.balance; // 공유 데이터를 다시 읽어온다.
        } finally {
            lock.unlockRead(stamp); // 읽기 lock을 푼다.
        }
    }
    return curBalance; // 낙관적 읽기 lock이 풀리지 않았으면 곧바로 읽어온 값을 반환
}
```

### ReentrantLock과 Condition
wait() & notify() 는 요리사 스레드와 손님 스레드를 구분해서 통지하지 못한다. wait() & notify() 로 스레드 종류를 구분하지 않고, 공유 객체의 waiting pool에 같이 몰아넣는 대신, 각 스레드 종류를 위한 Condition을 만들어서 각각의 waiting pool에서 따로 기다리도록 하면 문제는 해결된다.

Condition은 이미 생성된 lock으로부터 `newCondition()`을 호출해서 생성한다.

```java
private ReentrantLock lock = new ReentrantLock(); // lock을 생성

// lock으로 condition을 생성
private Condition forCook = lock.newCondition();
private Condition forCust = lock.newCondition();
```

위 코드에서 두 개의 Condition을 생성했는데, 하나는 요리사 스레드 하나는 손님 스레드를 위한 것이다. 그 다음엔, wait() & notify() 대신 Condition의 await() & signal() 을 사용하면 그걸로 끝이다.


## 9.4 volatile
멀티 코더 프로세서에서는 코어마다 별도의 캐시를 가지고 있어 공유 자원을 사용할 시 문제가 발생할 가능성이 있다.

그러나 변수 앞에 volatile을 붙이면 코어가 변수의 값을 읽어올 때 캐시가 아닌 메모리에서 읽어오기 때문에 캐시와 메모리 간의 값의 불일치가 해결된다.

### volatile로 long과 double을 원자화
JVM은 데이터를 4 byte(32bit)단위로 처리하기 때문에, int와 int보다 작은 타입들은 한 번에 읽거나 쓰는 것이 가능하다. 단 하나의 명령어로 읽거나 쓰기가 가능하다는 뜻이다.  
그리고 하나의 명령어는 더 이상 나눌 수 없는 최소 작업단위이므로 작업 중간에 다른 스레드가 끼어들 틈이 없다.

하지만 크기가 8 byte인 long과 double 타입의 변수는 하나의 명령어로 값을 읽거나 쓸 수 없기 때문에, 변수의 값을 읽는 과정에 다른 스레드가 끼어들 여지가 있다.  
다른 스레드가 끼어들지 못하게 하기 위해 변수를 읽고 쓰는 모든 코드를 synchronized 블럭으로 감쌀 수도 있지만, 더 간단한 방법이 있다. 변수를 선언할 때 volatile을 붙이는 것이다.

volatile은 해당 변수에 대한 읽기와 쓰기가 원자화된다. **원자화**라는 것은 더 이상 나눌 수 없게 한다는 의미인데, synchronized 블럭도 일종의 원자화라고 할 수 있다. 즉, synchronized 블럭은 여러 문장을 원자화함으로써 스레드의 동기화를 구현했다고 볼 수 있다.

volatile은 변수의 읽기와 쓰기를 원자화 할 뿐, 동기화를 하는 것은 아니다. 이것에 주의하자. synchronized 블럭으로 동기화하던걸 volatile로 대체할 수 없다.


## 9.5 fork & join 프레임웍
이 프레임웍은 하나의 작업을 작은 단위로 나눠서 여러 스레드가 동시에 처리하는 것을 쉽게 만들어준다.

수행할 작업에 따라 상속받을 클래스가 달라지는데, 두 클래스 중에 하나를 상속받아서 구현하면 된다.

- `RecursiveAction`: 반환값이 없는 작업을 구현할 때 사용
- `RecursiveTask`: 반환값이 있는 작업을 구현할 때 사용

두 클래스 모두 compute()라는 추상 메서드를 가지고 있는데, 클래스를 상속할 때 이 메서드를 구현하기만 하면 된다.

이 프레임웍은 스레드풀과 수행할 작업을 생성하고 invoke()로 작업을 시작한다. 스레드를 시작할 때 run()이 아니라 start()를 호출하는 것처럼, compute()가 아닌 invoke()로 시작한다.

ForkJoinPool은 이 프레임웍에서 제공하는 스레드풀로, 지정된 수의 스레드를 미리 생성해두어서 반복해서 재사용할 수 있게 한다. 그리고 이 스레드풀은 스레드가 수행해야하는 작업들을 담은 큐를 제공하며, 각 스레드는 자신의 작업 큐에 담긴 작업을 순서대로 처리한다.

### compute()의 구현
compute()를 구현할 땐 수행할 작업 외에 작업을 어떻게 나눌 것인지에 대한 것도 중요하다. 아래의 코드를 봐보자.

```java
public Long compute() {
    long size = to - from + 1; 
    
    if (size <= 5)
        return sum();
    
    long half = (from + to) / 2;
    
    SumTask leftSum = new SumTask(from, half);
    SumTask rightSum = new SumTask(half + 1, to);
    
    leftSum.fork(); // 작업 leftSum을 작업 큐에 넣는다.
    
    return rightSum.compute() + leftSum.join();
}
```

### 다른 스레드의 작업 훔쳐오기
fork()가 호출되어 작업 큐에 추가된 작업 역시, compute()에 의해 더 이상 나뉠 수 없을 때까지 반복해서 나뉘고, 자신의 작업 큐가 비어있는 스레드는 **다른 스레드의 작업 큐에서 작업을 가져와서 수행한다**. 이것을 작업 훔쳐오기(work stealing)라고 하며, 이 과정은 모두 스레드풀에 의해 자동적으로 이루어진다.

### fork()와 join()
fork()는 작업을 스레드의 작업 큐에 넣는 것이고, 작업 큐에 들어간 작업은 더 이상 나눌 수 없을 때까지 나뉜다. 즉 compute()로 나누고 fork()로 작업 큐에 넣는 작업이 계속해서 반복된다.

나눠진 작업은 각 스레드가 골고루 나눠서 처리하고, **작업 결과는 join()을 호출해서 얻을 수 있다**.

fork()와 join()의 중요한 차이점이 하나 있는데, fork()는 비동기 메서드이고, join()은 동기 메서드라는 것이다.

비동기 메서드는 결과를 기다리지 않는다. return문에서 compute()가 재귀호출될 때, join()은 호출되지 않는다. 그러다가 작업을 더 이상 나눌 수 없게 되었을 때, compute()의 재귀호출은 끝나고 join()의 결과를 기다렸다가 더해서 결과를 반환한다. 그래서 재귀호출된 compute()가 모두 종료될 때, 최종 결과를 얻게 된다.
