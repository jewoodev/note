MongoDB에서는 '마스터-슬레이브 복제'와 '레플리카 셋 복제'라는 두 가지의 복제 방식을 제공한다. 전자는 3.2 버전부터 Deprecated 방식으로 후자가 권장된다.

# 복제란?
복제는 여러 서버가 서로의 데이터를 동기화하는 것을 의미하는데, 서로 주고받는 데이터에 따라 논리 복제와 물리 복제로 나뉠 수 있다.  
물리적 복제는 DRBD처럼 리눅스 서버가 데이터의 내부를 전혀 모르는 상태에서 디스크의 블록만 복제하는 형태의 복제이다. 논리 복제는 데이터베이스 서버가 직접 서버 간에 데이터를 동기화하는 방식을 말한다.  
물리적 복제는 데이터베이스 서버가 전혀 관여하지 않으므로 운영체제 차원에서 응용 프로그램에 투명하게 복제를 처리할 수 있지만, 응용 프로그램의 캐시나 내부 처리 로직에서 변경된 데이터를 사용하지 못한다.   
특히 데이터베이스 서버처럼 복잡한 처리를 수행하는 응용 프로그램에서는 물리적 복제 방식은 장점보다 단점이 더 많은 편이다.

MongoDB는 MySQL 서버의 복제와 아주 비슷한 형태의 복제 기능을 가지고 있는데, 거기에 더해 프라이머리 노드의 선출과 네트워크 단절로 인한 스플릿 브레인(Split-Brain) 현상을 막을 수 있는 기능까지 내장하고 있다.

## 1. 컨센서스 알고리즘
여러 서버가 복제에 참여해 서로 같은 데이터를 동기화하는 형태에서 데이터를 공유하는 그룹을 **레플리카 셋**이라고 한다. 그리고 하나의 레플리카 셋의 멤버들은 프라이머리와 세컨더리로 역할이 나뉘어진다.  
레플리카 셋의 멤버들이 어떻게 서로의 데이터를 동기화하고, 특정 노드의 장애 발생 시 어떻게 대처할 것인지 등등에 대해 결정하는 것을 컨센서스 알고리즘이라고 하는데, MongoDB 서버는 확장된 형태의 *Raft 컨센서스 모델*을 사용한다.

*Raft 컨센서스 알고리즘*의 가장 큰 특징은 **리더 기반의 복제**와 각 멤버 노드가 **상태를 가진다**는 것이다.  
하나의 레플리카 셋에는 반드시 **리더가 하나만** 존재할 수 있고, 리더만이 사용자의 모든 데이터 변경 요청을 처리한다. 그리고 리더는 사용자의 데이터 변경 요청 내용을 로그에 기록하고, 모든 팔로워는 리더의 로그를 가져와서 동기화를 수행한다.  
Raft 컨센서스 알고리즘의 리더를 MongoDB에서는 프라이머리 노드라고 하며, 팔로워는 세컨더리 노드라고 한다. 그리고 로그를 OpLog라고 한다.

## 2. 복제의 목적
가장 큰 목적은 동일한 데이터를 이중 삼중으로 유지해서 특정 노드에서 데이터 손실이 발생하더라도 다른 멤버의 데이터로 대체할 수 있도록 하기 위함이다. 즉, **고가용성**을 위해 중복된 데이터 셋을 준비하는게 목적의 방향이다.

고가용성을 위해 MongoDb 레플리카 셋 멤버들은 서로 확인 메세지를 주고받는 걸 계속하는데, 이를 **하트비트 메시지**라고 한다. 만약 특정 멤버(프라이머리 멤버)가 통신이 되지 않으면, 다른 멤버들이 새로운 프라이머리 멤버를 선출해서 서비스가 지속적으로 처리될 수 있게 한다. 이렇게 새로운 프라이머리 멤버를 선출하는 과정은 MongoDB 샤딩이나 MongoDB 컨피그 서버와 무관하게 진행된다.

복제의 또 다른 목적으로는 데이터 조회 쿼리의 로드 분산이 있다. 고가용성을 위해 레플리카 셋에 너무 많은 멤버를 투입할 필요는 없다. 일반적으로 3대 정도의 서버로 구성하는데, 데이터 조회가 아주 많은 서비스에서는 로드 분산의 용도로 더 추가할 수도 있다. 데이터 쓰기 작업은 어차피 프라이머리 노드만 처리할 수 있기 때문에 멤버를 늘린다고 해서 성능을 높일 수 없다. 읽기 쿼리를 프라이머리에서 수행할지 세컨더리에서 수행할지 결정할 수 있도록 MongoDB 클라이언트 드라이버들은 **Read Preference 옵션**을 제공한다.

마지막으로 백업의 목적성도 어느정도 있다고 할 수 있다. 복제와 백업은 동떨어진 개념이지만, 백업을 실 서비스에서 활용하기에 애로사항이 있어서 그렇다.  
MongoDB는 아직 서비스 도중에 가능한 물리적인 백업 기능(온라인 물리 백업)을 제공하지는 않는다. 논리적인 백업은 서비스 도중에도 가능하지만 데이터 복구 시간이 상대적으로 길어서 긴급하게 데이터를 복구해야 하는 시점에는 도움이 되지 못할 수도 있다. 그래서 MongoDB에선 세컨더리 멤버를 멈추고 데이터 파일을 복사해야 할 수도 있다. 


# 레플리카 셋 멤버
하나의 MongoDB 레플리카 셋에는 최대 50개까지 멤버가 복제에 참여할 수 있다. 그런데 멤버끼리의 하트비트 메세지는 P2P 방식이므로 멤버 수가 많아질 수록 통신 비용이 매우 커진다. 따라서 불필요하게 많은 멤버를 추가하는 것은 피해야 한다.

그리고 멤버가 몇명이건 프라이머리 멤버 선출에 참여할 수 있는 멤버의 수는 7개이다. 선출 작업이 복잡한 과정을 거쳐야 하기 때문에 있는 전략이다. 따라서 멤버가 7개가 넘어서게 되면 7개 이외의 멤버는 Non-Voting 멤버로 설정돼야 한다.

## 1. 프라이머리
프라이머리 멤버는 레플리카 셋에서 데이터 변경을 처리할 수 있는 유일한 멤버다. 데이터 조회 쿼리도 처리할 수 있어 기본적으로는 프라이머리로 요청이 처리된다. 만약 특정 데이터 조회 쿼리를 세컨더리로 요청하고자 한다면 Read Preference 옵션을 조정해 쿼리를 실행하면 된다.

## 2. 세컨더리
하나의 레플리카 셋에서 세컨더리 멤버는 1개 이상 존재할 수 있으며, 프라이머리 멤버가 응답 불능 상태가 되면 투표를 통해 하나가 프라이머리 멤버가 된다. 그렇게 세컨더리 멤버가 프라이머리 멤버로 역할이 변경되는 걸 프로모션 또는 **스텝 업**이라고 한다.

세컨더리 멤버는 사용자의 데이터 변경 요청을 직접 처리할 수는 없지만 Read Preference 옵션을 이용해 읽기 요청은 처리할 수 있다. 이를 통해 읽기 쿼리의 부하를 분산할 수 있지만, 특정 세컨더리 멤버를 선택해서 요청하는 건 불가능하다. 응용 프로그램이 특정 세컨더리 멤버에 접속하지 못하도록 "hidden" 레플리카 셋 옵션을 이용할 수는 있다.

세컨더리 멤버는 고가용성과 읽기 쿼리의 부하를 분산시키는 용도로는 활용될 수 있지만, 데이터 백업의 용도로는 활용되기 어렵다. 프라이머리를 팔로업하면서 실시간으로 데이터를 동기화하므로 사용자의 실수 등으로 인해 프라이멤버에서 유실된 경우 세컨더리 멤버에도 유실되기 때문이다. 세컨더리에 지연된 복제를 적용해 이를 완화할 수는 있지만 한계가 있으므로 오프라인 상태의 백업은 필수다.

## 3. 아비터
아비터는 다른 역할을 하는 세컨더리 멤버로, 세컨더리 멤버와 다르게 프라이머리 노드와 데이터 동기화는 수행하지 않으면서, 프라이머리 선출에만 관여한다. 정족수를 채우기 위해 멤버가 필요한 경우에 주로 아비터를 사용한다. 

프라이머리 선출에는 레플리카 셋 멤버 수의 과반수 이상이 응답할 수 있는 상태여야 하는데, 불가능한 상태가 발생했을 때 아비터를 추가하는 것이 용이하다. 아비터가 아닌 멤버를 추가했을 때 초기 동기화 시간이 많이 들기 쉽기 때문이다. 


# 프라이머리 선출
레플리카 셋에 프라이머리 멤버가 없으면 데이터 변경 요청을 처리할 수 없게 되는 건 물론이고, Read Preference 옵션에 따라 때론 읽기 쿼리조차 불가능할 수 있다. 

## 1. 프라이머리 텀
여러 멤버가 동시에 투표를 하면 중복 투표가 발생할 위험이 있다. 그래서 MongoDB 3.2 이전 버전에서는 프라이머리 선출 투표는 30초에 한 번만 실행될 수 있게 설계됐다.  
그리고 중복 투표나 30초 대기 시간의 발생을 줄이고자 2단계 투표를 실행하도록 설계됐다. 사전 투표와 본 투표 두 단계로 나뉜다. 프라이머리가 되려는 세컨더리가 다른 멤버들에게 반대 여부를 확인하고, 반대하지 않으면 본 선거를 시작하는 것이다. 하지만 이는 복잡하여 프라이머리 텀이라는 개념이 도입됐다. 

프라이머리 텀은 사실 투표 식별자이며, 레플리카 셋의 각 멤버들이 프라이머리 선출을 시도할 때마다 1씩 증가하는 논리적인 시간 값이다. 각 멤버들은 투표 요청이 오면 30초 동안 기다리는 것이 아니라 프라이머리 텀 값을 기준으로 자기가 이미 투표를 했는지 아니면 다시 투표에 참여해야하는지 결정할 수 있다.   
그리고 프라이머리 텀은 투표할 때만 사용되는게 아니라, 프라이머리 멤버가 사용자 데이터 변경 요청을 실행한 다음에 변경 내용을 OpLog에 기록할 때마다 현재 프라이머리 텀 값을 같이 기록한다. 그 값으로 특정 OpLog가 어느 멤버가 프라이머리 멤버였을 때의 로그인지 식별한다.

항상 선출이 성공하는 것은 아니다. 실패하면 프라이머리 텀 값만 증가(예를 들어, 값이 3이다)하고 끝나게 된다. 그렇게 실패하면 텀 값을 또다시 증가(그럼 값이 4가 된다)시켜서 다시 새로운 투표를 시작하게 된다.

## 2. 프라이머리 스텝 다운
프라이머리에 장애가 생기거나 없어지는 상황 뿐 아니라 관리자가 의도적으로 프라이머리를 세컨더리로 내리는 것도 가능하다. 

- `rs.stepDown()` 명령으로 프라이머리를 스텝 다운
- `rs.reconfig()` 명령으로 레플리카 셋 멤버의 우선순위 변경

`rs.stepDown()` 명령은 다음의 2개의 인자를 사용할 수 있다.

```
rs.stepDown(stepDownSecs, secondaryCatchUpPeriodSecs)
```

`rs.stepDown()` 명령은 현재 프라이머리인 멤버에서만 실행할 수 있는데, 이 명령이 실행되면 명령을 요청받은 프라이머리는 즉시 프라이머리를 내려놓고 stepDownSecs 파라미터에 지정된 시간 동안 다시 프라이머리가 될 수 없다. 만약 그 시간동안 다른 세컨더리가 프라이머리가 되지 못하면 원래 프라이머리였던게 다시 될 가능성이 높다.

프라이머리가 빨리 선출되어야 사용자 요청을 빠르게 처리할 수 있겠지만, 기존의 프라이머리가 스텝 다운되는 시점에 다른 세컨더리가 그 프라이머리의 OpLog에서 모든 변경 사항을 가져왔다는 걸 보장하기 어렵다. 복제가 지연된 상황에선 많은 시간이 필요할 수 있기 때문에 두번째 인자인 secondaryCatchUpPeriodSecs 의 숫자만큼 새로 선출하지 않고 기다리면서 복제가 동기화되는 걸 기다린다. 다만, 복제가 다 완료되어도 그 값만큼 기다리지는 않고 바로 선출을 시작한다.

`rs.reconfig()` 는 우선순위를 변경하는데 이게 곧 프라이머리 스텝다운을 유발하게 된다(반드시는 아님). 프라이머리 노드는 자신보다 우선순위가 높은 멤버가 나타나면 그걸 인지하고 즉시 프라이머리 롤을 버리고 세컨더리로 전환하게 된다. 그리고 선출이 발생해 가장 높은 우선순위를 가진 멤버가 프라이머리가 된다.

## 3. 프라이머리 선출 시나리오
프라이머리는 정상적인데 네트워크 문제가 있어, 선출이 발생하면 프라이머리가 두 개가 되는 스플릿 브레인 현상이 발생할 수 있다. MongoDB는 이 현상을 막기 위해 과반수 이상의 멤버와 통신이 되지 않으면 자동으로 스텝 다운되도록 설계했다.

MongoDB 프라이머리 선출 알고리즘에서는 절대 다른 멤버를 후보로 추천하지 않는다. 기본적인 요건만 채워지면 자기 자신을 후보로 내세운다. 이를 Self-Election 이라 한다. 자신을 후보로 내세우며 다른 세컨더리에게 "다음 프라이머리 텀 값의 프라이머리가 되려 하는데 당신은 찬성하는가?" 라는 메세지를 전달한다. 그럼 수신한 멤버는 5가지 항목을 체크하고 모두 참이면 찬성 메세지를 보낸다. 그럼 그 텀 기간동안 프라이머리가 된다.

만약 5개의 체크 사항 중 하나라도 거짓이 나오면 거부 의사를 표시하는데, 레플리카 셋 멤버의 과반수 이상이 통신 가능한 상태에서만 투표를 실시할 수 있고, 하나라도 거부하면 선출에 실패하게 된다. 그런데 3.2 버전부터는 거부 의사를 표시할 필요가 없어졌다. 거부 대신 프라이머리 텀을 증가시키면 되기 때문이다. 

## 5. 롤백
MongoDB의 롤백은 RDBMS의 롤백과는 전혀 다른 의미를 갖는다. MongoDB의 롤백은 레플리카 셋의 각 멤버끼리 동기화하는 과정에서 이미 저장된(디스크에 영구적으로 기록됐었거나 저널 로그까지만 기록됐었거나) 데이터를 다시 삭제하는 과정을 말한다.

프라이머리 멤버가 네트워크 장애로 연결 불가 상태가 될 때 마지막 OpLog(5번이라고 명명)를 세컨더리가 복제하지 못한 상태로 불가 상태가 되고 나서, 새로운 프라이머리가 선출되고, 세컨더리 멤버로써 다시 레플리카 셋에 합류하면 다음과 같이 동기화한다.

자신이 가진 OpLog를 시간 역순으로 정렬해서 읽어온다. 그리고 그 순서대로 OpLog를 한 건씩 가져와서 새로운 프라이머리 멤버의 OpLog와 일치하는 게 있을 때까지 자신의 다음 OpLog와 새로운 프라이머리 멤버의 다음 OpLog를 매칭해본다. 그러다 공통되는 OpLog를 찾으면 자기 자신의 OpLog에서 공통으로 있는 OpLog 이후의 모든 OpLog를 삭제한다.  

이렇게 롤백 과정을 거치면서 삭제되거나 변경된 도큐먼트들은 MongoDB의 데이터 디렉터리의 "rollback" 이라는 디렉터리에 기록된다. 데이터베이스 관리자나 개발자는 이 디렉터리의 데이터를 이용해 필요한 재처리 작업을 수동으로 실행할 수 있다.

MongoDB의 롤백은 최대 300MB까지만 가능하다. 만약 세컨더리로 동기화되지 못한 데이터가 300MB를 넘을 정도로 많은 상태에서 프라이머리 스텝 다운이 발생하면 이 레플리카 셋 멤버는 새로운 프라이머리 멤버와의 동기화 지점을 찾지 못하고 에러 로그를 출력하며 중간에 복구를 멈춰버린다. 이런 경우엔 직접 수동으로 동기화 작업을 처리해야 한다.

그리고 이렇게 자동 롤백에 실패한 경우엔 복구해야 할 데이터가 rollback 디렉터리에 기록되지 않는다. 그러므로 잊지 말고 전체 데이터 파일을 백업하도록 하자.

# 복제 아키텍처
세컨더리는 프라이머리의 OpLog를 복제할 수도 있지만, 세컨더리 멤버의 OpLog를 재생할 수도 있다. 

OpLog의 재생은 실시간으로 변경되는 데이터에 동기화하는 것인데, 실제 MongoDB의 복제 동기화는 초기 동기화와 실시간 복제 두 단계로 나눠 볼 수 있다.

OpLog는 복제용 로그이며 다른 DBMS와 달리 MongoDB는 이 로그를 데이터베이스 서버의 "oplog.rs"라는 이름의 테이블(컬렉션)로 기록한다. 

MongoDB의 모든 컬렉션은 기본적으로 프라이머리 키 역할을 하는 "_id" 필드가 같이 저장돼야 한다. 하지만 OpLog 컬렉션은 특별한 형태(Capped Collection)의 컬렉션이기 때문에, "_id" 필드를 가지지 않으며 별도의 인덱스도 가질 수 없다. 

MongoDB의 OpLog는 Capped Collection으로 생성되는데, 이 컬렉션은 Tailable Cursor를 이용할 수 있다.

## 2. local 데이터베이스
oplog.rs도 컬렉션이면, 이 또한 데이터베이스에 존재하는 하나의 테이블에 속하는데, oplog.rs 컬렉션에 저장되는 INSERT 처리까지 세컨더리 멤버로 전달되버리면 이중으로 데이터가 전달되버린다. 어쩌면 계속 데이터 변경이 일어났다고 간주되어 oplog.rs에 계속 INSERT가 일어날지도 모른다. 다행히 프라이머리 멤버는 oplog.rs 컬렉션 자신에게 INSERT되는 데이터는 중복해서 저장하지 않는다.

그렇게 oplog.rs에서의 데이터 변경은 구별해내는 원리는 local 데이터베이스에 있다. oplog.rs 컬렉션이 이 데이터베이스에 있으며, 프라이머리 멤버는 local 데이터베이스 안의 컬렉션에서 발생하는 데이터 변경은 oplog.rs에 기록하지 않는다. 세컨더리 멤버에 동기화할 필요가 없거나 동기화를 원하지 않는 데이터가 있다면 이 데이터베이스를 활용하면 된다.

## 3. 초기 동기화
MongoDB 서버를 처음 설치하고 데이터 디렉터리가 완전히 비어 있는 상태로 레플리카 셋에 투입하면, 해당 서버는 이미 투입돼 있던 멤버로부터 모든 데이터를 일괄적으로 가져오는데 이 과정을 **초기 동기화**라고 한다.  
이런 초기 동기화 작업은 레플리카 셋에 처음 추가되거나 기존에 투입돼 있던 멤버가 다시 재시작하면서 레플리카 셋에 투입되면 실행된다. 다만 레플리카 셋에 투입되는 멤버의 데이터 디렉터리가 완전히 비어있는 경우에는 초기 동기화를 수행하고, 데이터 디렉터리에 이미 데이터가 있다면 초기 동기화 과정을 건너뛴다. 이미 데이터를 가지고 있는 MongoDB 서버를 복제의 새로운 멤버로 투입하는 걸 *부트스트랩*이라 한다.

MongoDB의 복제 초기 동기화 과정에 대해 다음 2가지 사항은 꼭 기억해두고 주의하자.

- 초기 동기화 작업은 단일 스레드로 진행되기 때문에 상당한 시간이 필요하다. 데이터의 복제도 단일 스레드지만 인덱스 생성도 하나씩 단일 스레드로 생성되므로 다른 DBMS보다 더 많은 시간을 예상해야 한다.
- 초기 동기화 작업은 중간에 멈췄다가 다시 시작하는 경우 처음부터 다시 시작해야 한다. 실제 초기 동기화 작업을 멈추고 다시 시작하는 명령은 없다. 따라서 초기 동기화를 멈추려면 MongoDB 서버를 종료해야 하며, MongoDB 서버를 다시 시작하면 초기 동기화를 시작하게 된다.

### 3.1 수동 초기 동기화
데이터 파일을 그대로 복사해서 새로운 멤버의 데이터 디렉터리에 위치시키는 방법이다. 데이터 파일을 물리적으로 복사하려면 기존 멤버의 MongoDB 서버를 종료하고 데이터가 변경되지 않는 상태에서 복사해야 한다. 만약 LVM 같이 스냅샷 백업이 있다면 그 백업을 사용해서 초기화할 수도 있다. 

이 방법을 사용할 땐 반드시 기본 멤버의 데이터 디렉터리에 있는 모든 데이터 파일(특히 local 데이터베이스 포함)을 그대로 가져와야 한다. 

> 이 방법을 쓸 땐 레플리카 셋의 멤버 중 최소 하나 이상은 백업된 시점의 OpLog를 가지고 있어야 한다. 없다면 복사 후 서버를 재시작해도 데이터를 동기화할 수 있는 멤버를 찾을 수 없어 동기화에 실패한다.

### 3.2 자동 초기 동기화
MongoDB 서버가 자동으로 다른 멤버로부터 데이터베이스를 복사하는 방법이다. 다음과 같은 과정을 거치게 된다.

1. **데이터베이스 복제**  
    새롱 추가되는 멤버는 레플리카 셋의 특정 멤버를 복제 소스로 선택하고, 그 멤버로 접속해 모든 데이터베이스의 모든 컬렉션을 쿼리해서 읽어온 다음 자신의 데이터베이스 컬렉션에 저장한다. 이렇게 초기 데이터를 가져오는 시점에는 컬렉션의 프라이머리 인덱스(_id)만 생성한 다음 복사를 실행하게 된다.인덱스가 많으면 많을 수록 INSERT 성능이 나빠져 시간이 오래 걸리기 때문에 프라이머리 인덱스만 생성하는 것이다.
2. **OpLog를 이용한 일시적인 데이터 동기화**  
    데이터베이스를 복제하는 과정은 상당히 오랜 시간이 필요하다. 하지만 OpLog의 용량은 제한적이기 때문에 너무 오랜 시간이 걸리면 초기 동기화가 실패한다. 그래서 인덱스를 생성하지 않고 데이터만 빠르게 복제한 다음에 즉시 밀려있던 OpLog를 동기화한다.
3. **인덱스 생성**  
    2번 작업까지 마치면 모든 인덱스를 생성하는 작업을 수행해 초기 동기화 작업을 마무리한다.

## 4. 실시간 복제
초기 동기화가 완료되면 세컨더리 멤버는 프라이머리나 다른 더 최신의 변경 정보를 가지고 있는 세컨더리 멤버로 연결한 다음 OpLog를 가져와서 재생하고, 자신의 OpLog에 기록한다. 이런 방식으로 동기화하기 때문에 언젠가는 프라이머리와 세컨더리의 데이터가 같아지는 것을 최종 일관성(eventual consistency)이라고도 표현한다.

### 4.1 복제 아키텍처
oplog.rs 컬렉션은 Cap Collection이다. 이 컬렉션은 범용 컬렉션(테이블)과는 달리 큐(Queue) 형태로 데이터가 저장되며, 데이터를 조회하는 작업 또한 큐와 동일한 형태로 처리된다.  
그리고 이 컬렉션의 가장 큰 특징 중 하나는 "Tailable cursor" 기능인데, 리눅스에서 로그 파일에 추가되는 내용을 실시간으로 보여주는 tail 명령과 비슷한 형태로 작동하는 커서다.  
Tailable cursor는 Cap Collection에서만 사용할 수 있는 커서로, OpLog가 저장되는 oplog.rs 컬렉션에 대해서 Tailable cursor를 생성하면 MongoDB 서버는 oplog.rs 컬렉션에 데이터가 추가될 때마다 커서를 통해서 최신 데이터를 보내주는 형태로 작동한다.

세컨더리 멤버의 Oplog 수집을 위한 백그라운드 스레드는 복제 소스로부터 OpLog를 가져와서 로컬 MongoDB의 메모리 큐에 저장한다.  
백그라운드로 OpLog를 수집하는 스레드인 옵저버(Observer)는 동기화 대상 멤버로부터 OpLog를 가져와서 큐에 담는 역할만 수행한다.  
여기에서 OpLog에 저장되는 큐는 최대 256MB를 넘어설 수 없다. 그래서 큐에 쌓인 OpLog를 OpLog 적용(Applier) 스레드가 빠르게 가져가지 못하면 옵저버 스레드는 큐에 여유 공간이 생길 때까지 기다리게 된다.

레플리케이션 배치 스레드는 큐에서 일정 개수의 OpLog를 가져와서 Applier 스레드 갯수에 맞게 작업량을 나눈 다음 OpLog 적용 스레드들에게 작업을 요청한다. 별도의 설정을 하지 않으면 OpLog 적용 스레드는 기본적으로 16개를 사용한다. 그리고 Applier 스레드는 각각 5,000개 정도의 OpLog 아이템을 담을 수 있는 자체 캐시 메모리가 있으며, 각 OpLog 아이템의 도큐먼트 크기가 너무 클 경우에 과도한 메모리 사용을 막기 위해 각 Applier 스레드는 최대 512MB의 메모리만 사용할 수 있게 되어있다. 그래서 16개의 OpLog 적용 스레드는 총 최대 8GB의 자체 캐시 메모리를 활용할 수 있다. 만약 이 스레드 갯수를 변경하려면 다음의 명령어를 사용하면 된다.

```
# MongoDB 설정 파일 변경
setParameter:
    replWriterThreadCount: 8
```

지금까지 개괄적인 아키텍처를 살펴봤다. 이제 세컨더리 멤버에서 OpLog가 적용되는 자세한 과정과 프라이머리와 세컨더리의 동기화 정보 교환 과정을 살펴보자. 

프라이머리 멤버는 모든 멤버의 복제 상태(각 멤버가 OpLog의 어디까지 동기화했는지에 관한 정보)를 가지고 있으며, 현재 프라이머리는 타임스탬프가 6번까지의 OpLog를 가지고 있는 상태이고, 나머지 세컨더리 멤버 2개는 타임스탬프 4번까지만 동기화한 상태라고 가정하자. 그리고 세컨더리 멤버의 복제 스레드는 프라이머리 멤버의 OpLog에 대해 Tailable cursor를 생성해서 프라이머리의 OpLog에 새로운 데이터가 기록됐는지 모니터링하고 있다. 

그런 상황에서 Tailable cursor는 프라이머리의 oplog.rs 컬렉션에 5번과 6번 OpLog 이벤트가 기록된 걸 확인하고 세컨더리의 옵저버 스레드로 결과를 내려준다. 해당 옵저버 스레드는 큐에 내려받은 OpLog를 저장하고 다시 프라이머리 OpLog 이벤트를 대기한다.  
큐에 OpLog가 저장되면 레플리케이션 배치 스레드는 큐에서 OpLog를 가져와서 Applier 스레드들에게 적절하게 작업을 분산시킨다. 

세컨더리 멤버가 OpLog 이벤트를 받았지만 프라이머리의 복제 상태 정보에는 세컨더리의 복제 동기화 상태가 여전히 타임스탬프 4로 유지된다. Applier 스레드는 각자 자기 자신에게 부여된 OpLog 이벤트를 서로 간섭없이 실행한다. 이때 Applier 적용 스레드가 실제 작업을 처리하기 직전에 세컨더리 MongoDB 서버의 레플리케이션 배치 스레드는 사용자의 쿼리 요청을 처리하지 못하도록 글로벌 쓰기 잠금을 건다. 그리고 OpLog 적용 스레드가 할당받은 OpLog 이벤트를 모두 처리하면 글로벌 쓰기 잠금을 해제하여 쿼리 요청을 처리할 수 있게 한다. 

일정 단위의 OpLog 재생이 완료되면 세컨더리는 즉시 자기 자신이 OpLog를 어디까지 처리햇는지 프라이머리 멤버에게 통보한다. 그러면 프라이머리는 세컨더리의 OpLog 동기화 위치 정보를 복제 상태 정보에 업데이트해서 세컨더리 멤버들의 동기화 정보를 최신 상태로 갱신한다. 

### 4.2 세컨더리 멤버의 읽기 일관성
세컨더리 멤버가 OpLog를 재생하는 시점에 쿼리를 블록킹하는 이유는 읽기 결과가 프라이머리에서 나타날 수 없는 상태를 세컨더리 멤버에서 보여주지 않기 위해서다. 즉, 프라이머리에서는 멀티 스레드로 사용자의 데이터 변경이 적용되고, 변경이 적용된 순서대로 OpLog에 순차적으로 기록된다. 하지만 세컨더리 멤버의 복제 스레드는 프라이머리로부터 OpLog를 가져와서 다시 멀티 스레드로 실행하는데, 세컨더리에서 OpLog가 재생되는 순서와 프라이머리에서 실행된 데이터의 변경 요청 처리 순서를 동일하게 유지하는 것이 불가능하기 때문이다. 그리고 이유는 재생 작업이 비동기, 멀티스레드로 수행되기 때문이다.

그래서 MongoDB에서는 세컨더리 멤버가 OpLog를 재생할 때 OpLog 이벤트를 특정 단위로 묶어서 한 번에 재생하는데, 이 순간에는 글로벌 쓰기 잠금을 이용해서 사용자의 쿼리 요청을 중단(블록킹)하는 것이다. 그리고 OpLog의 재생이 완료되고 잠금이 해제되면 최소한 이 시점에는 프라이머리와 동일한 상태의 데이터를 보여주게 된다. 

글로벌 잠금이 걸려있는 동안 프라이머리에서 쿼리를 실행하면 그 결과로 나올 수 있는 케이스는 다양하다.

- OpLog 1번만 적용된 상태
- 1번과 2번만 적용된 상태
- 1번부터 3번까지만 적용된 상태
- ...

만약 세컨더리가 OpLog를 적용할 때 글로벌 잠금을 걸지 않으면 OpLog 1번과 3번만 적용된 상태도 읽을 수 있게 된다. 

물론 이런 차이는 서비스의 특성에 따라서 사소한 차이일 수도 있지만, 때론 매우 민감한 문제일 수도 있다. 그래서 MongoDB 서버는 이런 문제를 원천적으로 차단하기 위해 OpLog를 청크 단위로 나눠서 각 청크를 멀티 스레드로 실행하며, 그 동안은 글로벌 잠금을 걸어서 사용자가 읽어가지 못하게 하는 것이다. 

