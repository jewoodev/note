MongoDB의 디폴트 스토리지 엔진이다. MongoDB가 이 엔진을 도입하기 전엔 MMAPv1 스토리지 엔진을 사용했는데, MMAPv1 스토리지 엔진은 범용적으로 사용하기엔 상당히 많은 문제점이 있었다. 그런 이유로 WiredTiger를 인수하고 MongoDB 서버에 내장하게 된 것이다.

WiredTiger 스토리지 엔진은 내부적인 잠금 경합을 최소화하기 위해 "하자드 포인터", "스킵 리스트" 같은 많은 신기술을 채택하고 있으며, 최신 RDBMS가 가지고 있는 MVCC(잠금 없는 데이터 읽기)와 데이터 파일 압축 그리고 암호회 기능들을 모두 가지고 있다.

# WiredTiger 스토리지 엔진 설정
MongoDB 서버의 설정 파일에서 설정할 수 있는 부분은 사실 그리 많지 않다. WiredTiger 스토리지 엔진에 대한 설정도 단순해서 성능과 연관된 설정은 2~3개 밖에 되지 않는다. 그리고 이 옵션들을 설정해도 기본값으로 설정되었을 때와 비교해서 성능 차이가 크지 않으며, 일반적으로 표준 설정을 그대로 사용해도 충분한 경우가 많다.

MongoDB 설정 파일에서 WiredTiger 스토리지 엔진과 관련된 부분을 살펴보자. 스토리지 엔진 공통 영역의 설정인 `storage` 세션의 설정은 주로 `dbPath` 나 `journal`과 관련된 설정만 자주 사용되고, 그 외 옵션은 자주 사용되진 않는다.

- `dbPath`: 데이터 파일을 저장할 경로를 설정한다. 다른 RDBMS와 달리 MongoDB 서버는 저널 로그나 OpLog가 모두 이 디렉터리의 하위에 저장된다. 만약 저널 로그나 OpLog를 다른 디스크나 파티션에 저장하고자 할 땐 디렉터리 단위로 심볼릭 링크(Symbolic Link)를 사용하는 것이 좋다. 그리고 OpLog를 분리하고자 할 땐 `directoryPerDB` 옵션을 `true`로 설정해서 데이터베이스 단위로 디렉터리가 생성되게 하는 것이 더 권장된다.
- `journal`: MongoDB 서버의 저널 로그를 활성화할 것인지를 결정한다. journal.enabled를 false로 설정하면 저널 로그(트랜잭션 로그)를 디스크에 저장하지 않는다. `journal.commitIntervalMs` 옵션은 저널 로그를 어느 주기로 디스크에 동기화할 것인지 결정한다. MongoDB 서버에서는 트랜잭션 단위로 저널 로그를 디스크에 동기화하지 않기 때문에 트랜잭션과 상관없이 commitIntervalMs 옵션에 설정한 밀리초 단위로 저널 로그를 디스크에 동기화한다.

`storage.engine` 항목은 MongoDB의 기본 스토리지 엔진으로 어떤 엔진을 사용할 것인지에 대한 설정이다. 그리고 `wiredTiger` 섹션이 WiredTiger 스토리지 엔진에 대한 설정 섹션인데, `engineConfig`와 `collectionConfig` 그리고 `indexConfig` 옵션으로 설정들을 오브젝트의 범위별로 설정할 수 있다. `engineConfig`는 WiredTiger 스토리지 엔진의 전역 설정이며, `collectionConfig`와 `indexConfig`는 각각 컬렉션과 인덱스에만 설정되는 옵션들을 명시할 수 있다. 주로 변경하는 옵션은 `engineConfig`의 `cacheSizeGB`와 `indexConfig`의 `prefixCompression`, 그리고 `collectionConfig`의 `blockCompressor` 정도다.


# WiredTiger 스토리지의 저장 방식
WiredTiger 스토리지 엔진은 다음과 같은 3가지 타입의 저장소를 가지고 있다.

- 레코드(Row, Record) 스토어
- 컬럼 스토어
- LSM(Log Structured Merge Tree) 스토어

레코드 스토어는 일반적인 RDBMS가 사용하는 저장 방식으로, 테이블의 레코드를 한꺼번에 같이 저장하는 방식이다. 기본적으로 B-Tree 알고리즘을 사용한다.

컬럼 스토어는 대용량의 분석(OLAP나 Data WareHouse) 용도로 자주 사용되는데, 테이블의 레코드와 상관없이 각 컬럼 단위 또는 컬럼의 그룹 단위로 데이터 파일을 관리한다. 이 방식은 특정 컬럼을 단위로 데이터 파일을 생성하므로 데이터 파일의 크기가 작아지고, 테이블의 전체 데이터를 읽어 들이는 속도가 빨라서 대용량 분석에 적합하다.

LSM은 HBase나 카산드라와 같은 NoSQL 데이터베이스에 자주 사용되는 방식으로, Read보단 Write 능력에 집중한 저장 방식이다. LSM은 내부적으로 B-Tree 알고리즘을 사용하지 않고 순차 파일 형태로 데이터를 저장하는데, 그런 순차 파일들이 시간 순서대로 1개 이상 관리되는 방식이다.

WiredTiger 스토리지 엔진은 이런 세 가지의 저장 방식을 가지고 있는데, 아직 MongoDB에 내장된 WiredTiger 스토리지 엔진은 레코드 기반의 저장소만 사용하고 있다. 


# 데이터 파일 구조
WiredTiger 스토리지 엔진은 앞서 이야기 했듯 `storage.directoryPerDB` 옵션으로 데이터베이스 별 디렉토리 구분을 할지 정할 수 있다. 데이터 파일들을 하나씩 살펴보자

## 1. WiredTiger
별도의 확장자를 갖지 않는 이 파일은 텍스트 파일로, 현재 실행 중인 WiredTiger 스토리지 엔진의 버전을 저장하고 있다. 

## 2. storage.bson
이 파일은 BSON 포맷으로 생성되며, WiredTiger의 디렉토리 구조를 설정하는 옵션의 내용이 저장되어 있다. 구체적으로 살펴보자면, MongoDB 서버의 데이터 파일을 처음 생성했는 시점의 `storage.directoryPerDB` 옵션과 `storage.wiredTiger.directoryForIndexes` 옵션의 값을 저장하고 있다.  
이 옵션들은 '컬렉션의 데이터 파일'과 '인덱스 저장 파일'을 어느 디렉토리에 위치시킬지 결정하는데, 한 번 데이터 파일이 초기화되면 변경할 수 없다. 

## 3. sizeStorer.wt
이 메타 데이터 파일은 WiredTiger 스토리지 엔진을 사용하는 컬렉션의 전체 도큐먼트 건 수와 각 컬렉션의 데이터 파일 크기를 저장한다. 이 파일은 WiredTiger 스토리지 엔진을 사용하는 일반 사용자 컬렉션과 동일하게 하나의 컬렉션으로 관리된다. 

## 4. WiredTiger.lock
MongoDB 서버가 사용하는 데이터 파일들을 다른 MongoDB 서버 인스턴스가 동시에 사용하지 못하도록 잠금 역할을 하기 위한 파일이다. 그리고 WiredTiger 스토리지 엔진이 정상적으로 셧다운 됐는지 판단하는데 쓰인다. 

MongoDB가 재시작되면서 WiredTiger 스토리지 엔진이 초기화될 때 WiredTiger.lock 파일이 남아있다면 WiredTiger는 MongoDB 서버가 비정상적으로 종료됐다고 판단하고 복구 모드를 시작한다. 만약 `WiredTiger.lock 파일을 강제로 삭제해버리면 MongoDB 서버가 비정상적으로 종료되더라도 WiredTiger 스토리지 엔진이 복구 모드를 실행하지 않아서 데이터가 손실될 수 있다.

## 5. WiredTiger.turtle
WiredTiger 스토리지 엔진의 설정 내용을 저장하고 있는 파일이다.  
이 파일은 WiredTiger 스토리지 엔진이 작동하기 위한 가장 기본적인 설정을 담고 있는 메타 데이터 파일이므로 반드시 백업에 같이 포함하고 변경되거나 삭제되지 않도록 주의하자.

## 6. _mdb_catalog.wt
MongoDB 서버가 가지고 있는 WiredTiger 스토리지 엔진 컬렉션과 인덱스의 목록, 그리고 각 인덱스나 컬렉션이 사용하는 데이터 파일의 목록을 관리하는 메타 데이터를 관리하는 파일이다.  
그 이외의 정보들도 포함하지만 WiredTiger 스토리지 엔진의 데이터 파일이어서 전용 도구가 아닌 이상 모든 내용을 확인하기는 어려운 상태이다. 

## 7. WiredTigerLAS.wt
WiredTiger 스토리지 엔진의 캐시에서 재활용할 수 있는 공간이 부족하면 WiredTiger 스토리지 엔진의 이빅션 서버가 여유 공간을 만들어야 사용자 요청 쿼리를 원활하게 처리할 수 있다.  
그런데 캐시에서 제거해야 하는 데이터 페이지들이 더티 페이지 상태라 디스크에 기록할 필요가 있다면 임시로 WiredTigerLAS.wt 데이터 파일을 사용하게 된다. 여기에 기록해뒀다가 다시 원래 데이터 파일로 기록되거나 쿼리를 처리할 때 캐시로 읽어와야 한다고 해서, 이 컬렉션의 이름이 Look Aside Table(LAS table)이라고 붙어진 것이다.

# WiredTiger의 내부 작동 방식
WiredTiger 스토리지 엔진은 대부분의 RDBMS와 구조가 닮아있다. MongoDB 서버가 트랜잭션을 지원하지 않기 때문에 WiredTiger 스토리지 엔진도 지원하지 않는다고 오해가 생기는데, WiredTiger 스토리지 엔진은 InnoDB 스토리지 엔진처럼 RDBMS 데이터 처리용 스토리지 엔진으로 개발됐다. 

WiredTiger 스토리지 엔진은 B-Tree 구조의 데이터 파일과 서버 크래시(비정상 종료)로부터 데이터를 복구하기 위한 저널 로그(WAL, Write Ahead Log)를 가지고 있다.  
WiredTiger의 저널 로그는 데이터 디렉토리 하위의 journal 디렉토리에 저장되며, 다른 RDBMS의 리두 로그(WAL)처럼 로테이션되면서 로그 파일의 로그 슬롯이 재활용 되는 방식이 아니라 새로운 로그 파일이 계속 생성된다. 그리고 체크포인트 시점 이전의 저널 로그는 더이상 필요하지 않으므로 자동으로 삭제하며 관리한다.  
일반적으로 WiredTiger 스토리지 엔진은 미리 3~10개 정도의 로그 파일을 미리 만들어 두고, 기존 저널 로그 파일(WiredTigerLog.0000N)을 다 사용하면 미리 만들어 둔 걸(WiredTigerPreplog.0000N) WiredTigerLog.0000N 으로 이름 변경하여 트랜잭션 로그를 기록한다.

WiredTiger 스토리지 엔진은 내장된 공유 캐시(버퍼 풀)를 가지고 잇다. WiredTiger의 내장된 공유 캐시는 디스크의 인덱스나 데이터 파일을 메모리에 캐시하여 빠르게 쿼리를 처리할 뿐 아니라, 데이터의 변경을 모아서 한 번에 디스크로 기록하는 쓰기 배치 기능을 모두 가지고 있다. 

사용자가 쿼리를 실행하면 WiredTiger 스토리지 엔진은 블록 매니저(Block Manager)를 통해 필요한 데이터 블록을 디스크에서 읽고, 공유 캐시에 적재해서 쿼리를 처리한다. 만약 사용자가 데이터를 변경하면 WiredTiger 스토리지 엔진은 트랜잭션을 시작하고 커서를 이용해서 원하는 도큐먼트의 내용을 변경한다.  
도큐먼트의 변경은 공유 캐시에 먼저 적용되는데, WiredTiger 스토리지 엔진은 변경된 데이터가 디스크에 기록되는 과정을 **기다리지 않고** 변경 내용을 저널 로그에 기록한 다음 사용자에게 작업 처리 결과를 리턴한다. 이는 `WriteConcern` 옵션에 따라 조금 달라질 수 있지만, 기본적으로는 그렇다. 그렇게 동작하며 공유 캐시에 데이터가 어느 정도 쌓이면 WiredTiger 스토리지 엔진은 체크포인트를 발생시켜서 공유 캐시의 더티 페이지를 모아 디스크에 기록한다. 이 때 메모리의 더티 페이지는 디스크에 기록하기 전에 가공 작업(원본 레코드와 변경된 정보의 병합)을 거쳐야 하는데, WiredTiger 스토리지 엔진의 리컨실리에이션(Reconciliation) 모듈이 이 작업을 담당한다.

WiredTiger 스토리지 엔진의 공유 캐시는 사용자가 설정한 크기의 메모리 범위 내에서 처리되어야 하므로 공간이 부족해지면 WiredTiger의 이빅션(Eviction) 모듈은 공유 캐시가 적잘한 메모리 사용량을 유지하도록 공유 캐시에서 자주 사용되지 않는 데이터 페이지들을 제거하는 작업을 수행한다. 만약 제거해야 하는 데이터 페이지가 더티 페이지라면 리컨실리에이션 모듈을 이용해 디스크에 데이터를 기록하고 공유 캐시에서 제거한다. 이런 과정 중 하나라도 처리가 느려지거나 문제가 생기면 쿼리 처리가 느려지게 된다.

WiredTiger 스토리지 엔진의 데이터 블록(페이지)은 모두 가변 사이즈다.  
오라클 DB나 MySQL 서버 같은 경우 모두 고정된 크기의 데이터 블록 사이즈를 사용한다. WiredTiger 스토리지 엔진의 블록 크기는 상한선이 있지만, 저장되는 실제 데이터 블록 크기는 고정적이지 않다. 고정 크기와 가변 크기의 데이터 블록 규칙은 각각 장단점이 있지만, 고정 크기인 경우 데이터 파일의 압축 기능을 구현하기 어렵다. 압축 결과물인 파일의 크기가 가변적인데, 이걸 고정된 크기의 데이터 블록에 저장해야 하므로 효율이 떨어지기 쉽기 때문이다.  
그래서 가변 크기의 블록을 사용하는 WiredTiger 스토리지 엔진에서는 데이터 파일의 압축이 선택 사항이라기보단 디폴트 옵션처럼 자주 사용되고 있다. 그런데 가변 크기의 블록을 사용하면 변경된 데이터 블록을 데이터 파일에 다시 기록할 때 적절히 빈 공간을 찾아서 저장하는 알고리즘이 필요하다.

WiredTiger 스토리지 엔진의 블록 매니저는 변경된 데이터 블록을 기록할 때, 프레그멘테이션을 최소화하면서 기록되는 데이터 블록의 크기에 최적인 위치를 찾아서 저장하는 역할을 담당한다. 그뿐 아니라 데이터 블록의 압축과 암호화 등과 같이 응용 프로그램에 투명하게 작동하는 기능을 모두 내장하고 있다. 


# 공유 캐시
WiredTiger 스토리지 엔진에서 사용자 쿼리는 공유 캐시를 거치지 않고 처리될 수 없으며 때로는 하나의 쿼리를 처리하기 위해 수천에서 수만 번 공유 캐시의 데이터 페이지를 참조해야 할 수도 있다. 그래서 공유 캐시의 최적화는 MongoDB의 처리 성능에 있어서 매우 중요한 역할을 담당한다. 그래서 공유 캐시의 사용량은 WiredTiger 스토리지 엔진을 모니터링하는데 있어서 필수적인 부분이다.

MongoDB 3.2 버전에 내장된 WiredTiger 스토리지 엔진의 공유 캐시 크기는 장착된 메모리의 60% - 1GB 이며, 이 값이 1GB보다 작으면 1GB로 설정된다. 3.4 버전부터 WiredTiger 스토리지 엔진의 공유 캐시는 기본적으로 전체 장착된 메모리의 50% - 1GB로 설정된다. 이 값이 256MB보다 작으면 256MB로 설정된다. 

공유 캐시는 MongoDB 서버를 재시작하지 않고도 크기를 조절할 수 있다. 하지만 그런 조절 작업은 WiredTiger 스토리지 엔진이 처리하고 있는 많은 '동시 처리 작업'들을 멈추고 수행되므로 쿼리 처리량이나 부하가 높을 때는 피할 필요가 있다. 

공유 캐시의 페이지는 매우 빈번하게 참조되므로 B-Tree의 각 페이지에 접근하는 방법에 따라 쿼리 성능도 많이 달라진다.  
일반적인 RDBMS는 디스크에 저장된 데이터 페이지 이미지를 그대로 공유 캐시에 적재한다. 그래서 공유 캐시에 적재된 B-Tree 노드를 통해 자식 노드를 찾아갈 때도 B-Tree 상의 주소를 사용한다.  
부모 노드를 통해 자식 노드를 찾아가는 과정에서 모두 테이블 스페이스와 데이터 페이지 번호를 통해 계속 찾아가게 된다. 결과적으로 트리를 찾아가는 과정에서 계속 페이지 주소와 실제 메모리 상의 주소의 맵핑을 참조하게 된다.  

하지만 WiredTiger 스토리지 엔진은 디스크의 데이터 페이지를 공유 캐시 메모리에 적재하면서 메모리에 적합한 트리 형태로 재구성하면서 적재한다.  
WiredTiger 스토리지 엔진의 공유 캐시에서 메모리에 적재된 페이지를 찾아가는 과정은 모두 별도의 맵핑 과정 없이 메모리 주소(C/C++ Pointer)를 이용해서 바로 검색할 수 있기 때문에 맵핑 테이블의 경합이나 오버헤드가 없다. 이 설명에서 유추할 수 있는데, WiredTiger 스토리지 엔진은 디스크에 저장되는 데이터 페이지의 레코드 인덱스를 별도로 관리하지 않는다. 대신 데이터 페이지를 공유 캐시 메모리에 적재할 때 레코드 인덱스를 새롭게 생성해서 메모리에 적재한다. 그리고 메모리에 적재하는 과정에서 WiredTiger 스토리지 엔진은 여러 가지 변환 과정을 거치기 때문에 데이터 페이지를 디스크에서 공유 캐시로 읽어 들이는 과정이 기존 RDBMS보다는 느리게 처리된다. 하지만 한 번 공유 캐시 메모리에 적재된 데이터 페이지에서 필요한 레코드를 검색하고 변경하는 작업은 기존의 RDBMS보다 훨씬 빠르고 효율적으로 작동한다.

그리고 공유 캐시의 객체에 대한 잠금 경합을 최소화하기 위해 Lock-Free 알고리즘을 채용하고 있다. WiredTiger 스토리지 엔진에서는 대표적으로 "하자드 포인터"와 "스킵 리스트" 자료 구조를 활용해 Lock-Free 콘셉을 구현하고 있다.

## 1. 하자드 포인터
하자드 포인트의 작동 원리를 알아보기 전에, 몇가지 개념을 어떻게 부를지 약속하고자 한다.  
"사용자 스레드"는 사용자의 쿼리를 처리하기 위해 WiredTiger 캐시를 참조하는 스레드이며, "이빅션 스레드"는 캐시가 다른 데이터 페이지를 읽어 들일 수 있도록 빈 공간을 만들어주는 역할을 담당하는 스레드다.

WiredTiger 스토리지 엔진의 모든 "사용자 스레드"는 WiredTiger 캐시의 데이터 페이지를 참조할 때, 먼저 하자드 포인터에 자신이 참조하는 페이지를 등록한다. 이 등록된 페이지는 이빅션 스레드가 자주 사용되지 않은 페이지를 골라서 삭제하려고 할 때 삭제되지 않는다.

WiredTiger 스토리지 엔진에서 사용할 수 있는 하자드 포인터의 최대 갯수는 기본적으로 1,000개로 제한되어 있다. 만약 하자드 포인터 갯수가 부족해서 WiredTiger 스토리지 엔진의 처리량이 낮아진다면 WiredTiger 스토리지 엔진의 옵션을 변경해서 갯수를 늘릴 수 있다.

## 2. 스킵 리스트
WiredTiger 스토리지 엔진에서 Lock-Free를 구현하기 위한 또 다른 기술이 스킵 리스트 자료 구조이다. 

스킵 리스트 자료 구조를 이해하기 위해 링크드 리스트와 비교를 해보려 한다. 링크드 리스트는 조회 구조가 단방향이며, 8번째 노드를 검색하려면 8번의 노드 검색이 필요하다. 스킵 리스트는 중간 노드를 갖는 여러 개의 리스트 층을 형성해 필요한 노드 검색 횟수를 줄인다. 이런 스킵 리스트의 평균 검색 기능은 B-Tree와 같은 O(log(n)) 이다.  
스킵 리스트는 B-Tree에 비해 검색 기능이 조금 떨어지긴 하지만, 구현이 간단하고 메모리 공간을 많이 필요로 하지 않는다. 그뿐만 아니라 WiredTiger 스토리지 엔진에 사용된 스킵 리스트는 새로운 노드를 추가하기 위해 잠금을 필요로 하지 않으며, 검색에도 필요하지 않다. 노드 삭제는 잠금을 필요로 하지만, B-Tree 자료 구조보다는 잠금을 덜 필요로 하므로 그다지 큰 성능 저하 이슈는 아니다. 

WiredTiger 스토리지 엔진도 다른 RDBMS와 동일하게 변경되기 전 레코드(언두 로그)를 별도의 저장 공간에 관리한다. 이렇게 언두 로그를 관리하는 이유는 트랜잭션이 롤백될 때 기존 데이터를 복구하기 위함인데, 많은 RDBMS에서는 언두 로그를 잠금 없는 데이터 읽기(MVCC) 용도로도 같이 사용한다. WiredTiger 스토리지 엔진에서는 언두 로그를 스킵 리스트로 관리하는데, 조금 독특하게 데이터 페이지의 레코드를 직접 변경하지 않고 변경 이후의 데이터를 스킵 리스트에 추가한다.

WiredTiger 스토리지 엔진에서는 데이터가 변경돼도 데이터 페이지에 변경된 내용을 직접적으로 변경하지 않는다. 대신 변경된 내용을 스킵 리스트에 차곡차곡 기록해둔다. 그리고 사용자 쿼리가 데이터를 읽을 땐 변경 이력이 저장된 스킵 리스트를 검색해서 원하는 시점의 데이터를 가져온다. 이런 방식의 의도는 쓰기 처리를 빠르게 하기 위함이다.

다른 RDBMS는 데이터가 변경되면서 크기가 커지면 데이터 페이지 내에서 레코드 위치를 옮겨야 할 수도 있는데, 이런 일련의 과정 때문에 성능 저하가 발생한다.  
그에 반해 WiredTiger 스토리지 엔진에서는 변경되는 내용을 스킵 리스트에 추가하기만 하면 된다. 그리고 그런 스킵 리스트에 내용을 추가하는 작업은 매우 빠르게 처리되므로 사용자의 응답 시간도 훨씬 빨라진다. 

일부 RDBMS에서 데이터 페이지는 한 시점에 하나의 스레드만 사용(읽고 쓰기)할 수 있다.  
그에 반해 WiredTiger 스토리지 엔진은 이런 관리 방식 덕분에 여러 스레드가 하나의 페이지를 동시에 읽고 쓸 수 있다.

# 캐시 이빅션
공유 캐시의 여유 공간을 적절하게 유지해서 필요한 데이터 페이지를 디스크에서 가져올 수 있게 하는 것이 중요하다.   
WiredTiger 스토리지 엔진은 이를 위해 이빅션 모듈을 가지고 있으며, 이를 "이빅션 서버" 라고도 한다. 이빅션 서버는 사용자의 요청을 처리하는 스레드(유저 스레드 or 포그라운드 스레드)와는 별개로 백그라운드 스레드로 실행되는데, 공유 캐시에 적재된 데이터 페이지 중에서 자주 사용되지 않는 데이터 페이지 위주로 공유 캐시를 제거하는 작업을 수행한다. WiredTiger 스토리지 엔진은 공유 캐시에 적재된 데이터 페이지를 스캔하면서 자주 사용되지 않는 페이지를 제거하는데, 이 과정에서 공유 캐시 스캔을 상당히 많이 수행하게 된다. 그리고 WiredTiger 캐시는 사용되는 빈도와 상관없이 가능하면 B-Tree의 브랜치 노드는 공유 캐시에 남겨두려는 경향이 있다.

그런데 SSD처럼 매우 빠르게 읽고 쓰기를 할 수 있는 저장 매체는 WiredTiger 스토리지 엔진의 '데이터 페이지 삭제' 속도보다 읽어 들이는 속도가 더 빨라질 수 있다. 그렇게 되면 WiredTiger 스토리지 엔진에서는 사용자 쿼리를 처리하는 프그라운드 스레드가 직접 캐시 이빅션을 수행한다. 당연히 이는 성능 저하로 이어진다. 

# 체크포인트
WiredTiger 스토리지 엔진도 사용자의 요청을 빠르게 처리하면서 커밋된 트랜잭션의 영속성을 보장하기 위해 트랜잭션 로그(WAL, 저널 로그)를 먼저 기록하고, 데이터 파일에 기록하는 작업은 사용자의 트랜잭션과 상관없이 뒤로 미뤄 처리한다. 이런 트랜잭션 DBMS들은 모두 '체크포인트'라는 개념을 가지고 있는데, 체크포인트는 데이터 파일과 트랜잭션 로그가 동기화 되는 시점을 의미한다. 

체크포인트는 DBMS 서버가 크래시되거나 서버가 응답 불능으로 인해서 비정상 종료됐다가 재시작됐을 때, 복구를 시작할 시점을 결정하는 기준이 된다. 그래서 체크포인트의 간격이 너무 길면 DBMS 서버의 복구 시간이 길어지게 되고, 너무 빈번하게 체크포인트가 발생하면 DBMS 서버가 쿼리를 처리하는 능력이 떨어진다.  

오라클 DBMS나 MySQL 서버의 InnoDB 스토리지 엔진은 퍼지(Fuzzy) 체크포인트 방식을 사용한다. 퍼지 체크포인트는 강제적으로 데이터 파일과 트랜잭션 로그를 최근 시점의 트랜잭션으로 동기화하는 게 아니라, 조금 오래전 시점에 발생했던 트랜잭션을 체크포인트 기준점으로 선택하는 방식을 말한다. 이런 방식은 문제가 발생했을 때 복구 시간이 좀 더 길어지지만, 체크포인트 실행 시점에 과다한 디스크 쓰기를 피할 수 있다.  
하지만 WiredTiger 스토리지 엔진은 샤프 체크포인트 방식을 채택하고 있다. 이 방식은 평상시엔 디스크 쓰기가 별로 많지 않지만, 체크포인트가 실행되는 시점에 한 번에 모아서 더티 페이지를 기록하는 패턴을 보인다.

WiredTiger 스토리지 엔진의 체크포인트가 처리되는 과정을 살펴보자.  
체크포인트가 실행되면, 변경된 페이지나 새로 추가된 페이지 중 리프 노드만 먼저 기록한다. 이때 새로 추가된 노드는 데이터 파일 내의 새로운 페이지 공간을 할당받아 기록한다. 그런데 변경된 페이지도 WiredTiger 스토리지 엔진은 기존의 데이터 페이지에 덮어쓰지 않고 새로운 페이지 공간을 할당받아서 저장한다.   
그렇게 리프 페이지의 데이터 파일이 저장완료되면 WiredTiger 스토리지 엔진은 변경된 B-Tree의 브랜치 노드를 데이터 파일에 기록한다. 브랜치 노드가 디스크의 데이터 파일로 기록되면서, 기록된 브랜치 노드의 리프 노드 중 변경되지 않은 리프 노드는 기존의 데이터 파일에 있던 데이터 페이지를 가리키도록 한다. 그런 과정을 거쳐 브랜치 노드가 모두 디스크에 기록되면 마지막으로 새로 만들어진 루트 노드를 디스크에 기록한다. 

그렇게 루트 노드까지 디스크의 데이터 파일에 기록되면 최종적으로 하나의 컬렉션에 대해 두 개의 B-Tree가 있게 된다. 변경된 모든 데이터의 디스크 기록시 완료되면 WiredTiger 스토리지 엔진은 컬렉션의 메타 데이터가 새로운 루트 노드를 가리키도록 변경한다. 컬렉션의 메타 정보가 가리키는 루트 노드가 변경되고 나면, 모든 사용자가 새로운 B-Tree에서 데이터를 조회하게 된다.

# MVCC
MVCC는 하나의 레코드(도큐먼트)에 대해서 여러 개의 버전을 동시에 관리하면서 필요에 따라 적절한 버전을 사용할 수 있게 해주는 기술이다.

# 데이터 블록
인덱스와 데이터 페이지 크기는 변동적으로 설정할 수 있다. 만약 대량의 INSERT와 분석이나 배치 작업을 위한 대량의 조회가 주요 접근 패턴이라면 가능하면 페이지의 크기를 크게 가져가는 게 좋다. 그리고 사용자가 주로 소규모의 도큐먼트를 아주 빈번하고 랜덤하게 읽고 변경하는 응용 프로그램에서는 가능하면 페이지의 크기를 작게 설정하는게 좋다.

배치나 분석 용도로 사용되는 경우라도 인덱스 페이지 크기는 기본값 이상으로 크게 설정하지 않는 편이 좋다.  
정렬되지 않은 필드값에 INSERT가 발생하면 인덱스의 모든 페이지들을 메모리에 적재해야 하고, 따라서 공유 캐시는 더 비효율적으로 작동하게 되기 때문이다. 

그리고 데이터 페이지의 크기를 키웠을 때도 비효율적인 효과가 생겨나는데 이 또한 쓰기 작업에서 공유 캐시가 낭비되어 비효율적으로 사용되는 것이 원인이다.
