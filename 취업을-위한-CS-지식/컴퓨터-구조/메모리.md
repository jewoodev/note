# RAM(Random Access Memory)
- RAM: 휘발성 저장장치(volatile memory)
  - 전원을 끄면 저장하고 있던 데이터와 명령어가 사라짐
  - CPU가 실행할 대상을 저장
- 보조기억장치: 비휘발성 저장장치(non-volatile memory)
  - 전원이 꺼져도 저장된 내용이 유지되며, 보관할 대상을 저장
- 임의 접근(random access) 또는 직접 접근(direct access)
  - 저장된 요소에 순차적으로 접근할 필요 없이 임의의 위치에 곧장 접근 가능한 방식
- 순차 접근(sequential access)
  - 특정 위치에 저장된 요소에 접근하기 위해 처음부터 순차적으로 접근하는 방식

1. DRAM
   - Dynamic RAM
     - 저장된 데이터가 동적으로 변하는(사라지는) 특성
       - 데이터의 소멸을 막기 위해 일정 주기로 데이터를 재활성화(다시 저장)
     - 비교적 DRAM의 소비 전력이 낮고, 저렴하며, 집적도가 높아 메모리를 대용량으로 설계하기에 용이
2. SRAM
   - Static RAM
     - 저장된 데이터가 변하지 않는 RAM
     - SRAM도 전원이 공급되지 않으면 저장된 내용이 소실
     - DRAM과 비교해 속도는 빠르지만, 소비 전력이 크고 가격도 비싼데다 집적도도 낮음
       - 대용량으로 만들 필요는 없지만 속도가 빨라야 하는 저장장치, 가령 캐시 메모리 등에서 사용
3. SDRAM
   - Synchronous Dynamic RAM
     - 클럭 신호와 동기화된, 보다 발전된 형태의 DRAM
     - 클럭 타이밍에 맞춰 CPU와 정보를 주고받을 수 있음
4. DDR SDRAM
   - Double Data Rate SDRAM
     - 대역폭을 넓혀 속도를 빠르게 만든 SDRAM
     - DDR2 SDRAM은 DDR SDRAM보다 대역폭이 두 배 넓은 SDRAM
     - DDR3, DDR4

---

# 메모리에 바이트를 밀어 넣는 순서 - 빅 엔디안과 리틀 엔디안
- 현대의 메모리는 대부분 데이터를 바이트 단위로 저장하고 관리
- 메모리는 데이터를 CPU로부터 바이트 단위로 받아들이지 않고, 일반적으로 4바이트, 혹은 8바이트인 워드 단위로 받아들임
- 여러 바이트로 구성된 데이터를 받아들여 여러 주소에 걸쳐 저장
  - 한 주소에 1바이트 씩 저장하는 메모리는 4바이트의 데이터를 4개의 주소에 저장하고, 8바이트의 데이터를 8개의 주소에 저장

- 빅 엔디안(big endian): 낮은 번지의 주소에 상위(더 큰) 바이트부터 저장하는 방식
  - 일상적으로 숫자 체계를 읽고 쓰는 순서와 동일하기 때문에 메모리 값을 직접 읽거나, 특히 디버깅할 때 편리
  - 주소에 1A, 2D, 3C, 4D의 순서대로 저장된 값 그대로 16진수 1A2D3C4D로 읽음

- 리틀 엔디안: 낮은 번지의 주소에 하위 바이트부터 저장하는 방식
  - 메모리 값을 직접 읽고 쓰기는 불편하지만 수치 계산이 편리하다는 장점

---

# 캐시 메모리
- CPU의 연산 속도와 메모리 접근 속도의 차이를 줄이기 위해 탄생
  - CPU와 메모리 사이에 위치한 SRAM 기반의 저장장치
- 코어와 가장 가까운 캐시 메모리는 L1 캐시(Level 1 cache)
  - 그 다음으로 가까운 캐시 메모리를 L2 캐시(Level 2 cache)
  - 그 다음으로 가까운 캐시 메모리를 L3 캐시(Level 3 cache)
- 일반적으로 L1 캐시와 L2 캐시는 코어 내부에, L3 캐시는 코어 외부에 위치

- 멀티코어 프로세서의 경우
  - 일반적으로 L1 캐시 메모리와 L2 캐시 메모리는 코어마다 고유한 캐시 메모리로 할당
  - L3 캐시는 여러 코어가 공유하는 형태로 구현

- 분리형 캐시(split cache)
  - L1I 캐시 - 명령어만을 저장하는 L1 캐시
  - L1D 캐시 - 데이터만을 저장하는 L1 캐시

## 캐시 히트와 캐시 미스
- 캐시 히트
  - 캐시 메모리가 예측하여 저장한 데이터가 CPU에 의해 실제로 사용되는 경우
- 캐시 미스
  - 틀린 예측으로 인해 CPU가 메모리로부터 필요한 데이터를 직접 가져와야 하는 경우
- 캐시 적중률(cache hit ratio)
  - 캐시가 히트되는 비율
  - 범용적으로 사용되는 컴퓨터의 캐시 적중률은 대략 85~95% 이상

## 참조 지역성의 원리
- 참조 지역성의 원리(locality of reference, principle of locality)
  - 특정한 원칙에 따라 메모리로부터 가져올 데이터를 결정
  - 시간 지역성: CPU는 최근에 접근했던 메모리 공간에 다시 접근하려는 경향
    - 변수
  - 공간 지역성: CPU는 접근한 메모리 공간의 근처에 접근하려는 경향
    - 배열

## 캐시 메모리의 쓰기 정책과 일관성
- 캐시 메모리에 데이터를 쓰는 경우
  - CPU가 캐시 메모리에 데이터를 쓸 때는 캐시 메모리에 새롭게 쓰여진 데이터와 메모리 상의 데이터가 일관성을 유지해야 함
  - ex) 현재 메모리 1000번지에 200이라는 값이 저장되어 있고, 이 값이 캐시 메모리에도 저장되어 있다고 가정
    - CPU가 이 값에 접근하고자 할 때는 당연히 앞서 배웠던 것처럼 캐시 메모리를 통해 값을 얻어냄
      - 이때 만약 CPU가 이 값을 200에서 300으로 바꾸고 싶다면?
        - 캐시 메모리부터 수정하고 메모리를 수정해야 함
- 캐시 메모리와 메모리 간의 불일치 방지
  - 즉시 쓰기(write-through): 캐시 메모리와 메모리에 동시에 쓰는 방법
    - 장점: 메모리를 항상 최신 상태로 유지하여 캐시 메모리와 메모리 간의 일관성이 깨지는 상황을 방지
    - 단점: 데이터를 쓸 때마다 메모리를 참조해야 하므로 버스의 사용 시간과 쓰기 시간이 늘어남
  - 지연 쓰기(write-back): 캐시 메모리에만 값을 써두었다가 추후 수정된 데이터를 한 번에 메모리에 반영
    - 장점: 메모리 접근 횟수를 줄일 수 있어 '즉시 쓰기 방식'에 비해 속도가 더 빠름
    - 단점: 메모리와 캐시 메모리 간의 일관성이 깨질 수 있다는 위험을 감수

- 캐시 메모리를 사용한다는 것, 나아가 캐싱을 한다는 것
  - 데이터 접근에 있어 어느 정도의 빠른 성능은 보장
    - 자주 사용할 법한 대상을 가까이 위치시킴으로써 성능 향상을 꾀함
  - 캐싱을 할 때는 언제나 캐시된 데이터와